<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Robot Vision & Learning (RVL) Lab | Continual Model-Based Reinforcement Learning with Hypernetworks</title>
<meta name="description" content="">

<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.17.0/css/mdb.min.css" integrity="sha256-/SwJ2GDcEt5382i8zqDwl36VJGECxEoIcBIuoLmLR4g=" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css"  integrity="sha256-h20CPZ0QyXlBuAw7A+KluUYx/3pK+c7lYEpqLTlxjYQ=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">
<link href="https://fonts.googleapis.com/css?family=Roboto+Condensed:400,700" rel="stylesheet">
   
<script src="//ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
<script src="/assets/js/splide-2.4.8/dist/js/splide.min.js"></script>
<script src="/assets/js/splide-2.4.8/dist/js/splide-extension-video.min.js"></script>
<link rel="stylesheet" href="/assets/js/splide-2.4.8/dist/css/splide.min.css">
<link rel="stylesheet" href="/assets/js/splide-2.4.8/dist/css/splide-extension-video.min.css">
<script src="/assets/js/app.js"></script>

   
<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.png">
<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/blog/2020/hypercrl/">

<!-- Open Graph -->

<meta property="og:site_name" content="" />
<meta property="og:type" content="object" />
<meta property="og:title" content="" />
<meta property="og:url" content="/blog/2020/hypercrl/" />
<meta property="og:description" content="Continual Model-Based Reinforcement Learning with Hypernetworks" />
<meta property="og:image" content="/assets/img/RVL_Edited-15.png" />


    <script src="/assets/js/distillpub/template.v2.js"></script>
    <script src="/assets/js/distillpub/transforms.v2.js"></script>
    
  </head>

  <d-front-matter>
    <script type="text/json">{
      "title": "Continual Model-Based Reinforcement Learning with Hypernetworks",
      "description": "",
      "published": "2020-08-18 00:00:00 -0400",
      "authors": [
        
        {
          "author": "Yizhou (Philip) Huang",
          "authorURL": "",
          "affiliations": [
            {
              "name": "University of Toronto",
              "url": ""
            }
          ]
        },
        
        {
          "author": "Kevin Xie",
          "authorURL": "",
          "affiliations": [
            {
              "name": "",
              "url": ""
            }
          ]
        },
        
        {
          "author": "Homanga Bharadhwaj",
          "authorURL": "",
          "affiliations": [
            {
              "name": "",
              "url": ""
            }
          ]
        },
        
        {
          "author": "Florian Shkurti",
          "authorURL": "",
          "affiliations": [
            {
              "name": "",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script>
  </d-front-matter>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light bg-white navbar-expand-sm fixed-top">
    <div class="container">

      
      
      
      
      
      <!-- a class="navbar-brand title font-weight-lighter" href="/">
       <span class="font-weight-bold">Robot</span> Vision  Lab
      </a-->
      
      <span class="navbar-lab-logo"><img src="/assets/img/RVL_Edited-15.png"></span> 
      
        
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item active">
            <a class="nav-link" href="/blog/">
              blog
              
            </a>
          </li>
          

	  
	  <!-- Other pages -->
	  
	  
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                publications
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/team/">
                team
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/joining/">
                joining
                
              </a>
          </li>
          
          
	  
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="post distill">

      <d-title>
        <h1>Continual Model-Based Reinforcement Learning with Hypernetworks</h1>
        <p></p>
      </d-title>

      <d-byline></d-byline>

      <d-article>
        <p>Effective planning in model-based reinforcement learning (MBRL) and model-predictive control (MPC) relies on the accuracy of the learned dynamics model. In many instances of MBRL and MPC, this model is assumed to be stationary and is periodically re-trained from scratch on state transition experience collected from the beginning of environment interactions. This implies that the time required to train the dynamics model – and the pause required between plan executions – grows linearly with the size of the collected experience. We argue that this is too slow for lifelong robot learning and propose <strong>HyperCRL, a method that continually learns the encountered dynamics in a sequence of tasks using task-conditional hypernetworks.</strong></p>

<p>Our method has three main attributes: first, it <strong>enables constant-time dynamics learning sessions between planning and only needs to store the most recent fixed-size portion of the state transition experience; second, it uses fixed-capacity hypernetworks to represent non-stationary and task-aware dynamics; third, it outperforms existing continual learning alternatives that rely on fixed-capacity networks, and does competitively with baselines that remember an ever increasing coreset of past experience.</strong> We show that HyperCRL is effective in continual model-based reinforcement learning in robot locomotion and manipulation scenarios, such as tasks involving pushing and door opening.</p>

<h3 id="code---paper"><a href="https://github.com/philip-huang/HyperCRL">Code</a> $~$  <a href="https://arxiv.org/abs/2009.11997">Paper</a></h3>

<h2 id="problem-setting">Problem Setting</h2>

<p>We consider the following problem setting: A robot interacts with the environment to solve a sequence of $T$ goal-directed tasks, each of which brings about different dynamics while having the same state-space $S$ and action space $A$. The robot is exposed to the tasks sequentially online without revisiting data collected in a previous task.</p>

<h2 id="our-method">Our method</h2>
<div>
  <img src="/assets/img/hypercrl/hypercrl_diag.png" alt="method diag" width="700" height="280" />
  <p></p>
</div>

<p>We have a learned dynamics model, the parameters of which are inferred through a task-conditioned hypernetwork. Given learned task embeddings and parameters of the hypernetwork, we infer parameters of the dynamics neural network. Using this dynamics model, we perform CEM optimization to generate action sequences and execute them in the environment for $K$ time-steps with MPC. We store the observed transitions in the replay dataset and update the parameters of the hypernetwork and task-embeddings. We repeat this for $M$ episodes per task, and for each of the $T$ tasks sequentially.</p>

<h2 id="video">Video</h2>

<h3 id="door-opening-with-a-panda-arm-2x-real-time">Door-opening with a Panda arm (2x real time)</h3>

<iframe width="560" height="315" src="https://www.youtube.com/embed/gsmLhP8WfKM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>A panda arm must be controlled to open a door. The reward function is designed such that the agent receives higher reward for opening the door to a wider angle. The agent is controlled using an operational space controller (both position and orientation). The different tasks correspond to different shapes of the door knob.</p>

<h3 id="pushing-a-non-uniform-cube-with-a-panda-arm-2x-real-time">Pushing a non-uniform cube with a Panda arm (2x real time)</h3>

<iframe width="560" height="315" src="https://www.youtube.com/embed/2fG-SJUXeNU" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>A panda arm must be controlled to push a block to a goal location without changing the oreintation of the block. The agent is controlled using an operational space controller (only position. orientation of the end-effector is fixed.). The different tasks correspond to different friction coefficients between the cube and the two sides of the table top</p>

<h3 id="sliding-a-block-towards-a-goal-location-1x-real-time">Sliding a block towards a goal location (1x real time)</h3>
<iframe width="560" height="315" src="https://www.youtube.com/embed/stKMNnGDa8U" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
<p>To move the second blue block to its goal pose, the panda arm should first hit block 1, which would slide away and in turn set the second block into sliding motion until stoopped by friction. The agent is controlled with an operational space controller similar to the pusher. The different tasks correspond to different friction coeffiecient between the second block and the table top</p>

<h2 id="results">Results</h2>

<h3 id="normalized-reward-on-the-door-environment-during-training">Normalized Reward on the Door Environment during training</h3>
<div>
  <img src="/assets/img/hypercrl/door_pose_reward-01.png" alt="method diag" width="690" height="230" />
  <p></p>
</div>

<h3 id="reward-on-the-pusher-environment-during-training">Reward on the Pusher Environment during training</h3>

<div>
  <img src="/assets/img/hypercrl/pusher_reward-01.png" alt="method diag" width="690" height="230" />
  <p></p>
</div>

<h3 id="reward-on-the-slider-environment-during-training">Reward on the Slider environment during training</h3>

<div>
  <img src="/assets/img/hypercrl/pusher_slide_reward-01.png" alt="method diag" width="690" height="230" />
  <p></p>
</div>

<hr />

<p>For more details, please check our paper!</p>

      </d-article>

      <d-appendix>
        <d-footnote-list></d-footnote-list>
        <d-citation-list></d-citation-list>
      </d-appendix>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2021 Robot Vision & Learning (RVL) Lab.
    
    
    Last updated: October 11, 2021.
    
  </div>
</footer>



  </body>

  <!-- Load Core and Bootstrap JS -->
<script src="https://code.jquery.com/jquery-3.4.1.slim.min.js" integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.0/umd/popper.min.js" integrity="sha256-OH05DFHUWzr725HmuHo3pnuvUUn+TJuj8/Qz9xytFEw=" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.17.0/js/mdb.min.js"  integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>

<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />


<!-- Load KaTeX -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" integrity="sha256-V8SV2MO1FUb63Bwht5Wx9x6PVHNa02gv8BgH/uH3ung=" crossorigin="anonymous" />
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.js" integrity="sha256-F/Xda58SPdcUCr+xhSGz9MA2zQBPb0ASEYKohl8UCHc=" crossorigin="anonymous"></script>
<script src="/assets/js/katex.js"></script>



<!-- Load Mansory & imagesLoaded -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/masonry/4.2.2/masonry.pkgd.min.js" integrity="" crossorigin="anonymous"></script>
<script src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>

<!-- Project Cards Layout -->
<script type="text/javascript">
  // Init Masonry
  var $grid = $('.grid').masonry({
    gutter: 10,
    horizontalOrder: true,
    itemSelector: '.grid-item',
  });
  // layout Masonry after each image loads
  $grid.imagesLoaded().progress( function() {
    $grid.masonry('layout');
  });
</script>







  <d-bibliography src="/assets/bibliography/">
  </d-bibliography>

</html>
