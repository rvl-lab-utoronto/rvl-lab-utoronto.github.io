(this["webpackJsonprvl-lab-utoronto"]=this["webpackJsonprvl-lab-utoronto"]||[]).push([[0],{113:function(e,t,n){},120:function(e,t,n){},126:function(e,t,n){},127:function(e,t,n){"use strict";n.r(t),t.default=n.p+"static/media/bars-solid.e8db7520.svg"},357:function(e,t,n){},358:function(e,t,n){},359:function(e,t,n){},360:function(e,t,n){},361:function(e,t,n){"use strict";n.r(t),t.default=n.p+"static/media/florian.ef061895.jpg"},362:function(e,t,n){},363:function(e,t,n){"use strict";n.r(t),t.default=n.p+"static/media/expand_more.8322b254.svg"},371:function(e,t,n){"use strict";n.r(t),t.default=n.p+"static/media/caret-left-solid.f3619997.svg"},372:function(e,t,n){"use strict";n.r(t),t.default=n.p+"static/media/caret-right-solid.572aedcd.svg"},373:function(e,t,n){},374:function(e,t,n){},375:function(e,t,n){},378:function(e,t,n){},384:function(e,t,n){},385:function(e,t,n){"use strict";n.r(t),t.default=n.p+"static/media/envelope-solid.80b23b18.svg"},386:function(e,t,n){"use strict";n.r(t),t.default=n.p+"static/media/twitter-brands.87682341.svg"},387:function(e,t,n){"use strict";n.r(t),t.default=n.p+"static/media/linkedin-brands.f4041044.svg"},388:function(e,t,n){"use strict";n.r(t),t.default=n.p+"static/media/graduation-cap-solid.af8ffce9.svg"},389:function(e,t,n){"use strict";n.r(t);var a=n(2),i=n.n(a),o=n(31),s=n.n(o),r=(n(113),n(11)),c=n(18),l=n(14),d=n(405),h=n(403),p=n(4),u=n(7),b=n(5),m=n(6),g=n(0),j=function(e){Object(b.a)(n,e);var t=Object(m.a)(n);function n(){return Object(p.a)(this,n),t.apply(this,arguments)}return Object(u.a)(n,[{key:"componentDidUpdate",value:function(e){this.props.location.pathname!==e.location.pathname&&window.scrollTo(0,0)}},{key:"render",value:function(){return Object(g.jsx)("div",{})}}]),n}(i.a.Component),v=Object(l.g)(j),f=n(32),x=n.n(f),O=n(88),y=n(43),k=(n(120),n(58)),w=n(101),S=n(102),C=(n(121),n(89)),I=n.n(C),A=n(90),_=(n(126),[{link:"https://www.youtube.com/channel/UCrDIJSrZ5I46topcN6MoF7g",name:"YouTube",icon:"assets/social-icons/youtube.png"},{link:"https://twitter.com/florian_shkurti",name:"Twitter",icon:"assets/social-icons/twitter.png"},{link:" https://github.com/rvl-lab-utoronto",name:"GitHub",icon:"assets/social-icons/github.png"},{link:"https://vectorinstitute.ai/",name:"Vector Institute",icon:"assets/social-icons/vector institute.png"},{link:"https://robotics.utoronto.ca/",name:"UofT Robotics Institute",icon:"assets/social-icons/university.png"},{link:"https://robotics.cs.toronto.edu/",name:"CS Robotics",icon:"assets/social-icons/robot-arm.png"}]),R=function(e){Object(b.a)(a,e);var t=Object(m.a)(a);function a(){var e;return Object(p.a)(this,a),(e=t.call(this)).handlePageChange=function(t){var n=e.getCurrentPageName(t);e.setState({currentLink:t,currentName:n.title,open:!1})},e.getCurrentPageName=function(e){for(var t=Object.keys(Te),n=0;n<t.length;n++)for(var a=0;a<Te[t[n]].length;a++)if(e===Te[t[n]][a].link)return{title:Te[t[n]][a].title,category:t[n]};return{title:"",category:""}},e.navbarPages=Te,e.navbarPagesTotal=Object(r.a)(e.navbarPages.main),e.state={open:!1,currentLink:"",currentName:""},e.firstOpen=!0,e.state={open:!1},e}return Object(u.a)(a,[{key:"render",value:function(){var e=this;return Object(g.jsxs)("div",{className:"navbar",children:[Object(g.jsx)("div",{className:"desktop-view",children:Object(g.jsxs)("div",{className:"navbar-flex horizontal-padding max-width-home",children:[Object(g.jsx)("div",{style:{width:"250px"},children:Object(g.jsx)(c.b,{to:"/",children:Object(g.jsx)("img",{alt:"RVL",className:"rvl-icon-desktop",src:n(71).default})})}),Object(g.jsx)("div",{children:this.navbarPagesTotal.map((function(t,n){return Object(g.jsx)(T,{selected:e.state.currentLink===t.link,title:t.title,link:t.link})}))}),Object(g.jsx)("div",{className:"navbar-socials",style:{width:"250px"},children:_.map((function(e,t){return Object(g.jsx)(g.Fragment,{children:Object(g.jsx)(P,{social:e},e.name)})}))})]})}),Object(g.jsxs)("div",{className:"mobile-view",children:[Object(g.jsxs)("div",{className:"navbar-flex",style:{zIndex:100,backgroundColor:"white"},children:[Object(g.jsx)(c.b,{to:"/",children:Object(g.jsx)("img",{alt:"RVL",className:"rvl-icon-mobile",src:n(71).default})}),Object(g.jsx)("div",{style:{height:"50px"}}),Object(g.jsx)("div",{className:"navbar-socials",style:{position:"absolute",right:"38px",top:"10px"},children:_.map((function(e,t){return Object(g.jsx)(g.Fragment,{children:Object(g.jsx)(P,{social:e},e.name)})}))}),Object(g.jsx)("img",{onClick:function(){e.setState({open:!e.state.open})},alt:"menu",className:"navbar-menu-icon",src:n(127).default})]}),Object(g.jsx)("div",{className:"navbar-items-mobile "+(this.state.open?"":"navbar-items-mobile-open"),children:this.navbarPagesTotal.map((function(t,n){return Object(g.jsx)(M,{selected:e.state.currentLink===t.link,title:t.title,link:t.link})}))})]})]})}}]),a}(a.Component),T=function(e){Object(b.a)(n,e);var t=Object(m.a)(n);function n(){return Object(p.a)(this,n),t.apply(this,arguments)}return Object(u.a)(n,[{key:"render",value:function(){return Object(g.jsx)(c.b,{to:this.props.link,className:"navbar-link-text "+(this.props.selected?"navbar-link-text-selected":""),children:this.props.title})}}]),n}(a.Component),M=function(e){Object(b.a)(n,e);var t=Object(m.a)(n);function n(){return Object(p.a)(this,n),t.apply(this,arguments)}return Object(u.a)(n,[{key:"render",value:function(){return Object(g.jsx)(c.b,{to:this.props.link,className:"navbar-link-text-mobile "+(this.props.selected?"navbar-link-text-selected-mobile":""),children:this.props.title})}}]),n}(a.Component),P=function(e){Object(b.a)(n,e);var t=Object(m.a)(n);function n(){return Object(p.a)(this,n),t.apply(this,arguments)}return Object(u.a)(n,[{key:"render",value:function(){return Object(g.jsx)("a",{className:"navbar-social",href:this.props.social.link,style:{textDecorationColor:"transparent"},children:Object(g.jsx)("img",{alt:this.props.social.name,className:"navbar-social-image",src:"/rvl-lab-utoronto.github.io/"+this.props.social.icon})})}}]),n}(a.Component),L=function(e){Object(b.a)(n,e);var t=Object(m.a)(n);function n(){return Object(p.a)(this,n),t.apply(this,arguments)}return Object(u.a)(n,[{key:"render",value:function(){return Object(g.jsxs)(g.Fragment,{children:[Object(g.jsx)("div",{className:"mobile-view",children:Object(g.jsx)("div",{style:{marginTop:"80px"}})}),Object(g.jsx)("div",{className:"desktop-view",children:Object(g.jsx)("div",{style:{marginTop:"80px"}})})]})}}]),n}(a.Component),D=n(404),E=n(399),F=function(e){Object(b.a)(n,e);var t=Object(m.a)(n);function n(){return Object(p.a)(this,n),t.apply(this,arguments)}return Object(u.a)(n,[{key:"render",value:function(){var e=Object(g.jsxs)(g.Fragment,{children:[Object(g.jsx)("div",{style:{height:"5px"}}),Object(g.jsx)("h2",{children:this.props.blog.title}),this.props.blog.date?Object(g.jsx)("p",{style:{margin:"1px",marginTop:"5px",marginBottom:"5px",color:"black"},children:this.props.blog.date}):Object(g.jsx)(g.Fragment,{}),this.props.blog.description?Object(g.jsx)("p",{style:{margin:"1px",color:"black"},children:this.props.blog.description}):Object(g.jsx)(g.Fragment,{}),Object(g.jsx)("div",{style:{height:"25px"}}),Object(g.jsx)("hr",{})]});return void 0!==this.props.blog.asset&&""!==this.props.blog.asset&&void 0!==this.props.blog.webLocation&&""!==this.props.blog.webLocation?Object(g.jsx)(c.b,{className:"blog-entry-link",to:"/blog/"+this.props.blog.webLocation,children:e}):void 0!==this.props.blog.link&&""!==this.props.blog.link?Object(g.jsx)("a",{className:"blog-entry-link",href:this.props.blog.link,children:e}):e}}]),n}(a.Component);function N(e){var t=e.replaceAll('"assets/','"/rvl-lab-utoronto.github.io/assets/');return t=t.replaceAll("'assets/","'/rvl-lab-utoronto.github.io/assets/")}var z=function(e){Object(b.a)(n,e);var t=Object(m.a)(n);function n(e){var a;return Object(p.a)(this,n),(a=t.call(this,e)).state={text:""},a}return Object(u.a)(n,[{key:"componentDidMount",value:function(){var e=Object(y.a)(x.a.mark((function e(){var t,n,a,i,o,s,r,c,l,d;return x.a.wrap((function(e){for(;;)switch(e.prev=e.next){case 0:if(this.props.distill){e.next=14;break}return e.next=3,fetch(this.props.src);case 3:return t=e.sent,e.next=6,t.text();case 6:n=e.sent,a=N(a=Object(A.decode)(I.a.renderToString(Object(g.jsx)(g.Fragment,{children:Object(g.jsx)(k.a,{remarkPlugins:[w.a],rehypePlugins:[S.a],children:n})})))),i=a.split("<pre><code>"),o=[i[0]],s=Object(O.a)(i.splice(1));try{for(s.s();!(r=s.n()).done;)c=r.value,l=("<pre><code>"+c).split("</code></pre>"),d=l[0].trimEnd(),o.push(d),o.push(l[1])}catch(h){s.e(h)}finally{s.f()}this.setState({htmlSplit:o});case 14:case"end":return e.stop()}}),e,this)})));return function(){return e.apply(this,arguments)}}()},{key:"render",value:function(){return this.props.distill?Object(g.jsxs)(g.Fragment,{children:[Object(g.jsx)("div",{style:{height:"55px"}}),Object(g.jsx)("iframe",{id:"iframe",style:{width:"100vw",height:"calc(100vh - 8px - 55px)"},title:"blogPost",src:this.props.src})]}):""!==this.state.htmlSplit?Object(g.jsxs)(g.Fragment,{children:[Object(g.jsx)(L,{}),Object(g.jsx)("div",{children:Object(g.jsx)("div",{className:"center",children:Object(g.jsxs)("div",{className:"horizontal-padding max-width-blog blog-entry-page",children:[!0===this.props.removeExtraSpace?Object(g.jsx)("div",{}):Object(g.jsx)("div",{style:{height:"25px"}}),void 0!==this.props.articleData?Object(g.jsxs)(g.Fragment,{children:[Object(g.jsx)("h1",{style:{fontWeight:600},children:null===(e=this.props.articleData)||void 0===e?void 0:e.title}),void 0!==this.props.articleData.authors||void 0!==this.props.articleData.date||void 0!==this.props.articleData.affiliations?Object(g.jsxs)(g.Fragment,{children:[Object(g.jsx)("div",{style:{height:"20px"}}),Object(g.jsx)("hr",{}),Object(g.jsx)("div",{style:{height:"10px"}}),Object(g.jsxs)("div",{className:"article-data",children:[void 0!==this.props.articleData.authors?Object(g.jsxs)("div",{style:{display:"flex",flexDirection:"column"},children:[Object(g.jsx)("h4",{className:"article-data-header",children:"Authors"}),null===(t=this.props.articleData)||void 0===t||null===(n=t.authors)||void 0===n?void 0:n.map((function(e){return Object(g.jsx)("h3",{className:"article-data-label",children:e})}))]}):Object(g.jsx)(g.Fragment,{}),void 0!==this.props.articleData.affiliations?Object(g.jsxs)("div",{style:{display:"flex",flexDirection:"column"},children:[Object(g.jsx)("h4",{className:"article-data-header",children:"Affiliations"}),null===(a=this.props.articleData)||void 0===a||null===(i=a.affiliations)||void 0===i?void 0:i.map((function(e){return Object(g.jsx)("h3",{className:"article-data-label",children:e})}))]}):Object(g.jsx)(g.Fragment,{}),void 0!==this.props.articleData.date?Object(g.jsxs)("div",{style:{display:"flex",flexDirection:"column"},children:[Object(g.jsx)("h4",{className:"article-data-header",children:"Published"}),Object(g.jsx)("h3",{className:"article-data-label",children:null===(o=this.props.articleData)||void 0===o?void 0:o.date})]}):Object(g.jsx)(g.Fragment,{})]}),Object(g.jsx)("div",{style:{height:"10px"}}),Object(g.jsx)("hr",{})]}):Object(g.jsx)(g.Fragment,{}),Object(g.jsx)("div",{style:{height:"16px"}})]}):Object(g.jsx)(g.Fragment,{}),this.state.htmlSplit&&this.state.htmlSplit.map((function(e){if(e.startsWith("<pre><code>")){var t=e.split("<pre><code>")[1];return Object(g.jsx)(D.a,{language:"javascript",style:E.a,children:t})}return Object(g.jsx)("div",{dangerouslySetInnerHTML:{__html:e}})}))]})})})]}):Object(g.jsx)(g.Fragment,{});var e,t,n,a,i,o}}]),n}(a.Component),G=(n(357),function(e){Object(b.a)(n,e);var t=Object(m.a)(n);function n(){return Object(p.a)(this,n),t.apply(this,arguments)}return Object(u.a)(n,[{key:"render",value:function(){return Object(g.jsx)("div",{className:"footer",children:Object(g.jsx)("p",{className:"accent-paragraph footer-copyright",style:{color:"gray"},children:"\n  \xa9 Robot Vision & Learning (RVL) Lab. All rights reserved. \n"})})}}]),n}(a.Component)),H=[{title:"Learning to Search in Task and Motion Planning with Streams",date:"September 14, 2021",link:"https://rvl.cs.toronto.edu/learning-based-tamp/"},{title:"Continual Model-Based Reinforcement Learning with Hypernetworks",date:"August 18, 2020",webLocation:"hypercrl-md",asset:"assets/blog-pages/hypercrl.md",articleData:{title:"Continual Model-Based Reinforcement Learning with Hypernetworks",date:"August 18, 2020",authors:["Yizhou (Philip) Huang","Kevin Xie","Homanga Bharadhwaj","Florian Shkurti"],affiliations:["University of Toronto"]}}],V=function(e){Object(b.a)(n,e);var t=Object(m.a)(n);function n(){return Object(p.a)(this,n),t.apply(this,arguments)}return Object(u.a)(n,[{key:"render",value:function(){return Object(g.jsx)("div",{className:"center",children:Object(g.jsxs)("div",{className:"horizontal-padding max-width",children:[Object(g.jsxs)("div",{style:{minHeight:"100vh"},children:[Object(g.jsx)(L,{}),Object(g.jsx)("div",{style:{height:"1px"}}),H.map((function(e){return Object(g.jsx)(F,{blog:e})}))]}),Object(g.jsx)("div",{style:{position:"absolute",left:0,width:"100vw"},children:Object(g.jsx)(G,{})})]})})}}]),n}(a.Component),B=(n(358),n(359),[{title:"autonomous robots for environmental monitoring",content:[],asset:"assets/research-themes/autonomous robots.jpg",web:"/research/autonomous-robots"},{title:"learning to plan, perceive, and control",content:[],asset:"assets/research-themes/machine learning.jpg",web:"/research/machine-learning"},{title:"safe robot learning",content:[],asset:"assets/research-themes/safe robot learning.jpg",web:"/research/safe-robot"}]),J=function(e){Object(b.a)(n,e);var t=Object(m.a)(n);function n(){return Object(p.a)(this,n),t.apply(this,arguments)}return Object(u.a)(n,[{key:"render",value:function(){var e=this;return Object(g.jsxs)(g.Fragment,{children:[Object(g.jsx)("h2",{className:"research-theme-title",children:"Research Themes"}),Object(g.jsx)("div",{className:"research-themes-box-container",children:B.map((function(t,n){return void 0===e.props.indexesToShow||e.props.indexesToShow.includes(n)?Object(g.jsx)(g.Fragment,{children:Object(g.jsx)(U,{themes:B[n].content,theme:t})}):Object(g.jsx)("div",{})}))})]})}}]),n}(a.Component),U=function(e){Object(b.a)(n,e);var t=Object(m.a)(n);function n(){return Object(p.a)(this,n),t.apply(this,arguments)}return Object(u.a)(n,[{key:"render",value:function(){return Object(g.jsxs)("div",{className:"research-themes-box",children:[Object(g.jsx)("h3",{children:Object(g.jsx)(c.b,{to:this.props.theme.web,children:this.props.theme.title})}),this.props.themes.map((function(e,t){return Object(g.jsx)("p",{children:e})}))]})}}]),n}(a.Component),K=(n(360),function(e){Object(b.a)(a,e);var t=Object(m.a)(a);function a(){return Object(p.a)(this,a),t.apply(this,arguments)}return Object(u.a)(a,[{key:"render",value:function(){return Object(g.jsx)(g.Fragment,{children:Object(g.jsxs)("div",{className:"lab-intro-box-container",children:[Object(g.jsx)("div",{className:"lab-intro-box",children:Object(g.jsx)("img",{src:n(361).default,alt:""})}),Object(g.jsxs)("div",{className:"lab-intro-box-text",children:[Object(g.jsx)("h2",{children:"Welcome"}),Object(g.jsxs)("p",{children:[" Welcome to the Robot Vision and Learning (RVL) lab. We are part of the ",Object(g.jsx)("a",{href:"https://web.cs.toronto.edu/",children:"Computer Science"})," department at the ",Object(g.jsx)("a",{href:"https://www.utoronto.ca/",children:"University of Toronto"}),", the ",Object(g.jsx)("a",{href:"https://www.utm.utoronto.ca/math-cs-stats/",children:"MCS"})," department at ",Object(g.jsx)("a",{href:"https://www.utm.utoronto.ca",children:"UTM"}),", and the ",Object(g.jsx)("a",{href:"https://robotics.utoronto.ca/",children:"UofT Robotics Institute"}),". The group is led by ",Object(g.jsx)("a",{href:"http://www.cs.toronto.edu/~florian/",children:"Prof. Florian Shkurti"}),", and consists of students with backgrounds in robotics, machine learning, engineering, control theory, and physics."]}),Object(g.jsx)("p",{children:"We develop methods that enable robots to perceive, reason, and act effectively and safely, particularly in dynamic environments and alongside humans. Application areas include field robotics for environmental monitoring, visual navigation for autonomous vehicles, and mobile manipulation."})]})]})})}}]),a}(a.Component)),W=(n(362),[{date:"2022-03-1",content:"Our paper on <a href='https://openaccess.thecvf.com/content/CVPR2022/html/Khorasgani_SLIC_Self-Supervised_Learning_With_Iterative_Clustering_for_Human_Action_Videos_CVPR_2022_paper.html'>video representation learning</a> was accepted to CVPR for oral presentation. "},{date:"2022-02-1",content:"Our paper on <a href='https://arxiv.org/abs/2110.07668'>equivariant representations for imitation learning</a> was accepted to ICRA. "},{date:"2021-08-12",content:"Two papers accepted at CoRL, one on <a href='https://openreview.net/forum?id=nWLt35BU1z_'>task planning in large 3D scene graphs</a>, and one on <a href='https://openreview.net/forum?id=tCfLLiP7vje'>perceiving transparent objects from RGBD sensors</a> (oral). "},{date:"2021-07-07",content:"Our paper on <a href='https://nv-tlabs.github.io/physics-pose-estimation-project-page/'>physics-based human motion tracking and synthesis from videos</a> was accepted at ICCV.  "},{date:"2021-05-07",content:"Florian received an <a href='https://www.amazon.science/research-awards/recipients?f0=2020&f1=00000173-2161-da60-a1f3-b9f59a740001&s=0'>Amazon Research Award</a>. "},{date:"2021-02-28",content:"Three papers accepted at ICRA, one on <a href='https://arxiv.org/abs/2009.11997'>continual model-based RL</a>, one on <a href='https://arxiv.org/abs/2005.10934'>reachability based exploration in RL</a>, and one on <a href='https://arxiv.org/abs/2011.01298'>handling imperfect demonstrations in imitation and RL</a>. "},{date:"2021-02-28",content:"One paper accepted at CVPR, <a href='https://arxiv.org/abs/2103.03891'>on latent space disentanglement in GANs for image synthesis</a>. "},{date:"2021-01-12",content:"Three papers accepted at ICLR, one on <a href='https://openreview.net/forum?id=iaO86DUuKi'>safe reinforcement learning</a>, one on <a href='https://openreview.net/forum?id=jXe91kq3jAq'>learning transferable skills for hierarchical planning</a>, and one on <a href='https://openreview.net/forum?id=c_E8kFWfhp0'>differentiable physics and rendering simulators</a>. "},{date:"2020-12-2",content:"Florian is co-organizing the NeurIPS 2020 <a href='https://montrealrobotics.ca/diffcvgp/'>workshop on differentiable computer vision, graphics, and physics</a>. "},{date:"2020-12-2",content:"Our <a href='https://arxiv.org/abs/2003.04514'>paper</a> on encouraging diversity in neural network ensembles was accepted at AAAI. "},{date:"2020-07-20",content:"<a href='https://www.youtube.com/watch?v=AeMSp-_hSnU'>Our work</a>, led by collaborators <a href='http://www.cim.mcgill.ca/~travism/'>Travis</a>, <a href='http://www.cim.mcgill.ca/~gamboa/'>Juan Camilo</a>, <a href='https://ca.linkedin.com/in/stefan-wapnick-00b122a6'>Stefan</a> and others, won the Best Paper Award in the RSS'20 Workshop on Self-Supervised Robot Learning."},{date:"2020-07-2",content:"Two papers accepted at IROS. One on <a href='https://arxiv.org/abs/2003.10010'>visual search</a> and one on <a href='https://arxiv.org/abs/2003.07489'>mobile manipulation</a>.   "},{date:"2020-06-05",content:"Florian co-organized the <a href='https://starslab.ca/workshops/icra_2020_debates/'>Debates on the Future of Robotics Research</a> workshop at ICRA 2020."},{date:"2020-05-07",content:"<a href='http://www.roboticsproceedings.org/rss16/p048.html'>Our paper on vision-based navigation</a> was accepted at RSS. "}]),Y=function(e){Object(b.a)(a,e);var t=Object(m.a)(a);function a(){var e;return Object(p.a)(this,a),(e=t.call(this)).amountShow=10,e.amountShowExpand=10,e.state={show:e.amountShow},e}return Object(u.a)(a,[{key:"render",value:function(){var e=this;return Object(g.jsxs)(g.Fragment,{children:[Object(g.jsx)("h2",{className:"news-title",children:"News"}),Object(g.jsxs)("div",{className:"news-box-container",children:[W.map((function(t,n){return n>=e.state.show?Object(g.jsx)(g.Fragment,{}):Object(g.jsx)("div",{className:"news-box",children:Object(g.jsx)("p",{dangerouslySetInnerHTML:{__html:'<span class="boxed">'+Z(t.date)+" "+X(t.date)+"</span> "+t.content}})})})),this.state.show>=W.length?Object(g.jsx)(g.Fragment,{}):Object(g.jsx)("div",{style:{width:"100%",marginTop:"10px"},className:"center",children:Object(g.jsx)("div",{onClick:function(){e.setState({show:e.state.show+e.amountShowExpand})},className:"news-load-more-button",children:Object(g.jsx)("img",{alt:"more",style:{height:"24px",width:"24px"},src:n(363).default})})})]})]})}}]),a}(a.Component);function X(e){return void 0===e||3!==e.split("-").length?"":e.split("-")[0]}var q=["Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sept","Oct","Nov","Dec"];function Z(e){return void 0===e||3!==e.split("-").length?"":q[parseInt(e.split("-")[1])-1]}var Q=n(8),$=(n(364),n(98)),ee=["assets/slideshow/husky_utm_2020.png","assets/slideshow/arm_farm.jpg","assets/slideshow/utah_flying_1.png","assets/slideshow/boat_1.jpg","assets/slideshow/boat_2.jpg","assets/slideshow/visual_search_diver_tracking_iros_2020.png","assets/slideshow/ball_catching_ke.gif"],te=function(e){Object(b.a)(a,e);var t=Object(m.a)(a);function a(){return Object(p.a)(this,a),t.apply(this,arguments)}return Object(u.a)(a,[{key:"render",value:function(){return Object(g.jsx)($.Carousel,Object(Q.a)({infiniteLoop:!0,children:!1,labels:!1,showStatus:!1,showThumbs:!1,emulateTouch:!0,renderArrowPrev:function(e,t,a){return t&&Object(g.jsx)("div",{style:{cursor:"pointer",position:"absolute",zIndex:1,top:"50%",transform:"translateY(-50%)",left:"10px",opacity:"0.7",backgroundColor:"white",borderRadius:"30px",width:"30px",height:"30px",display:"flex",justifyContent:"center",alignItems:"center"},onClick:e,children:Object(g.jsx)("img",{alt:"previous",style:{height:"20px",width:"20px",paddingRight:"2px"},src:n(371).default})})},renderArrowNext:function(e,t,a){return t&&Object(g.jsx)("div",{style:{cursor:"pointer",position:"absolute",zIndex:1,top:"50%",transform:"translateY(-50%)",right:"10px",opacity:"0.7",backgroundColor:"white",borderRadius:"30px",width:"30px",height:"30px",display:"flex",justifyContent:"center",alignItems:"center"},onClick:e,children:Object(g.jsx)("img",{alt:"next",style:{height:"20px",width:"20px",paddingLeft:"2px"},src:n(372).default})})}},"children",ee.map((function(e){return Object(g.jsx)("img",{style:{borderRadius:"7px"},src:"/rvl-lab-utoronto.github.io/"+e,alt:"slideshow"})}))))}}]),a}(a.Component),ne=function(e){Object(b.a)(n,e);var t=Object(m.a)(n);function n(){return Object(p.a)(this,n),t.apply(this,arguments)}return Object(u.a)(n,[{key:"render",value:function(){return Object(g.jsxs)(g.Fragment,{children:[Object(g.jsx)("div",{className:"desktop-view",children:Object(g.jsx)("div",{className:"horizontal-padding max-width-home",children:Object(g.jsxs)("div",{style:{display:"flex",flexDirection:"row"},children:[Object(g.jsxs)("div",{className:"left-section",children:[Object(g.jsx)(te,{}),Object(g.jsx)("div",{style:{height:"20px"}}),Object(g.jsx)(K,{}),Object(g.jsx)("div",{style:{height:"20px"}}),Object(g.jsx)(J,{})]}),Object(g.jsx)("div",{className:"news-section",children:Object(g.jsx)(Y,{})})]})})}),Object(g.jsx)("div",{className:"mobile-view",children:Object(g.jsxs)("div",{className:"horizontal-padding",children:[Object(g.jsx)(te,{}),Object(g.jsx)(K,{}),Object(g.jsx)(J,{}),Object(g.jsx)(Y,{})]})})]})}}]),n}(a.Component),ae=n(103),ie=function(e){Object(b.a)(a,e);var t=Object(m.a)(a);function a(e){var n;return Object(p.a)(this,a),(n=t.call(this,e)).state={readme:""},n}return Object(u.a)(a,[{key:"componentDidMount",value:function(){var e=Object(y.a)(x.a.mark((function e(){var t,a,i;return x.a.wrap((function(e){for(;;)switch(e.prev=e.next){case 0:return e.next=2,n.e(4).then(n.bind(null,406));case 2:return t=e.sent,console.log(t),e.next=6,fetch(t.default);case 6:return a=e.sent,console.log(a),e.next=10,a.text();case 10:i=e.sent,this.setState({readme:i});case 12:case"end":return e.stop()}}),e,this)})));return function(){return e.apply(this,arguments)}}()},{key:"render",value:function(){return""===this.state.readme?Object(g.jsx)("div",{}):Object(g.jsx)("div",{className:"center",children:Object(g.jsx)("div",{className:"horizontal-padding max-width",children:Object(g.jsx)(k.a,{rehypePlugins:[ae.a],children:this.state.readme})})})}}]),a}(a.Component),oe=[{title:"Autonomous robots for environmental monitoring",description:"",image:"assets/project-assets/images/placeholder1.jpg",asset:"assets/project-assets/pages/autonomous-robots.md",webLocation:"autonomous-robots"},{title:"Learning to plan, perceive, and control",description:"",image:"assets/project-assets/images/placeholder2.jpg",asset:"assets/project-assets/pages/machine-learning.md",webLocation:"machine-learning"},{title:"Safe robot learning",description:"",image:"assets/project-assets/images/placeholder3.jpg",asset:"assets/project-assets/pages/safe-robot.md",webLocation:"safe-robot"}],se=(n(373),function(e){Object(b.a)(n,e);var t=Object(m.a)(n);function n(){return Object(p.a)(this,n),t.apply(this,arguments)}return Object(u.a)(n,[{key:"render",value:function(){var e=Object(g.jsxs)("div",{className:"project-box",children:[Object(g.jsx)("img",{alt:this.props.project.name,className:"project-image",src:"/rvl-lab-utoronto.github.io/"+this.props.project.image}),Object(g.jsx)("div",{style:{display:"flex",flexDirection:"column",justifyContent:"center"},children:Object(g.jsxs)("div",{className:"project-box-content",children:[Object(g.jsx)("h3",{style:{margin:0},children:this.props.project.title}),void 0!==this.props.project.description&&""!==this.props.project.description?Object(g.jsx)("p",{dangerouslySetInnerHTML:{__html:this.props.project.description}}):Object(g.jsx)(g.Fragment,{})]})})]});return void 0!==this.props.project.link&&""!==this.props.project.link?Object(g.jsx)("a",{href:this.props.project.link,className:"no-decoration",children:e}):void 0!==this.props.project.asset&&""!==this.props.project.asset&&void 0!==this.props.project.webLocation&&""!==this.props.project.webLocation?Object(g.jsx)(c.b,{className:"no-decoration",to:"/research/"+this.props.project.webLocation,children:e}):Object(g.jsx)("div",{className:"no-hover",children:e})}}]),n}(a.Component)),re=function(e){Object(b.a)(n,e);var t=Object(m.a)(n);function n(){return Object(p.a)(this,n),t.apply(this,arguments)}return Object(u.a)(n,[{key:"render",value:function(){return Object(g.jsx)(z,{src:this.props.src,removeExtraSpace:!0})}}]),n}(a.Component),ce=n(57),le={default:3,985:2,600:1},de=function(e){Object(b.a)(n,e);var t=Object(m.a)(n);function n(){return Object(p.a)(this,n),t.apply(this,arguments)}return Object(u.a)(n,[{key:"render",value:function(){return Object(g.jsx)("div",{className:"center",children:Object(g.jsxs)("div",{className:"horizontal-padding max-width",children:[Object(g.jsx)("div",{style:{height:"10px"}}),Object(g.jsx)(ce.a,{breakpointCols:le,className:"masonry-grid",children:oe.map((function(e){return Object(g.jsx)(se,{project:e})}))})]})})}}]),n}(a.Component),he=n(15),pe=(n(374),function(e){Object(b.a)(n,e);var t=Object(m.a)(n);function n(){return Object(p.a)(this,n),t.apply(this,arguments)}return Object(u.a)(n,[{key:"render",value:function(){var e=this;return Object(g.jsx)(g.Fragment,{children:Object(g.jsx)("input",{value:this.props.value,style:Object(he.a)(Object(he.a)({},this.props.style),{},{fontSize:"15px"}),type:"text",placeholder:this.props.placeholder,onChange:function(t){return e.props.onChange(t.target.value)}})})}}]),n}(a.Component)),ue=[{bibtex:"\n\n       @InProceedings{Wei_2023_CVPR,\n          author    = {Cong Wei and Brendan Duke and Ruowei Jiang and Parham Aarabi and Graham Taylor and Florian Shkurti},\n          title     = {Sparsifiner: Learning Sparse Instance-Dependent Attention for Efficient Vision Transformers},\n          booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n          month     = {June},\n          year      = {2023},\n          pages     = {22680-22689}\n       }         \n    ",html:"https://arxiv.org/abs/2303.13755",tags:["computer vision","robot vision"],thumbnail:"/assets/publication-thumbnails/cvpr23-sparsifiner.png",description:""},{bibtex:"\n\n      @InProceedings{Gu_2023_CVPR,\n         author    = {Qiao Gu and Dongsub Shim and Florian Shkurti},\n         title     = {Preserving Linear Separability in Continual Learning by Backward Feature Projection},\n         booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n         month     = {June},\n         year      = {2023},\n         pages     = {24286-24295}\n      }\n        \n    ",html:"https://arxiv.org/abs/2303.14595",tags:["computer vision","robot vision","continual learning"],code:"https://github.com/rvl-lab-utoronto/BFP",thumbnail:"/assets/publication-thumbnails/cvpr23-bfp.png",description:""},{bibtex:"\n\n      @article{jatavallabhula2023conceptfusion,\n          title={ConceptFusion: Open-set Multimodal 3D Mapping}, \n          author={Krishna Murthy Jatavallabhula and Alihusein Kuwajerwala and Qiao Gu and Mohd Omama and Tao Chen and Shuang Li and Ganesh Iyer and Soroush Saryazdi and Nikhil Keetha and Ayush Tewari and Joshua B. Tenenbaum and Celso Miguel de Melo and Madhava Krishna and Liam Paull and Florian Shkurti and Antonio Torralba},\n          year={2023},\n      booktitle={Robotics: Science and Systems (RSS)},\n      }\n        \n    ",html:"https://arxiv.org/abs/2302.07241",tags:["computer vision","robot vision"],code:"https://concept-fusion.github.io/",video:"https://concept-fusion.github.io/",thumbnail:"/assets/publication-thumbnails/rss23-conceptfusion.gif",description:""},{bibtex:"\n        \n       @article{Khodeir2023PolicyGuidedLS,\n         title={Policy-Guided Lazy Search with Feedback for Task and Motion Planning},\n         author={Mohamed Khodeir and Atharv Sonwane and Ruthrash Hari and Florian Shkurti},\n         booktitle={IEEE International Conference on Robotics and Automation (ICRA)},\n         year={2023},\n       }\n    ",html:"https://arxiv.org/abs/2210.14055",tags:["task and motion planning","manipulation"],code:"https://github.com/rvl-lab-utoronto/policy-guided-lazy-tamp",data:"https://github.com/rvl-lab-utoronto/policy-guided-lazy-tamp",video:"https://www.youtube.com/watch?v=HjSZOVkXSLU&t=1s&ab_channel=MohamedKhodeir",thumbnail:"/assets/publication-thumbnails/icra23-policy-guided-tamp.png",description:""},{bibtex:"\n      @article{https://doi.org/10.48550/arxiv.2111.13144,\n       author = {Mohamed Khodeir and Ben Agro and Florian Shkurti},\n       title = {Learning to Search in Task and Motion Planning with Streams},\n       journal = {Robotics and Automation Letters (RA-L)},\n       year = {2023},\n       volume={abs/2111.13144}\n    }\n\n    ",html:"https://arxiv.org/abs/2111.13144",tags:["task and motion planning","manipulation"],video:"https://rvl.cs.toronto.edu/learning-based-tamp/",code:"https://rvl.cs.toronto.edu/learning-based-tamp/",data:"https://rvl.cs.toronto.edu/learning-based-tamp/",thumbnail:"/assets/publication-thumbnails/ral23-learning-to-search.png",description:""},{bibtex:"\n \n        @article{Huang2022StochasticPF,\n           title={Stochastic Planning for ASV Navigation Using Satellite Images},\n           author={Yizhou Huang and Hamza Dugmag and Tim D. Barfoot and Florian Shkurti},\n           booktitle={IEEE International Conference on Robotics and Automation (ICRA)},\n           year={2023},\n        }\n\n    ",html:"https://arxiv.org/abs/2209.11864",tags:["planning","field robotics","robot vision"],code:"https://pcctp.github.io/",data:"https://pcctp.github.io/",video:"https://pcctp.github.io/",thumbnail:"/assets/publication-thumbnails/icra23-asv-navigation.png",description:""},{bibtex:"\n\n      @article{wang2023mvtrans,\n          title={MVTrans: Multi-View Perception of Transparent Objects}, \n          author={Yi Ru Wang and Yuchi Zhao and Haoping Xu and Saggi Eppel and Alan Aspuru-Guzik and Florian Shkurti and Animesh Garg},\n          year={2023},\n          booktitle={IEEE International Conference on Robotics and Automation (ICRA)},\n      }        \n    ",html:"https://arxiv.org/abs/2302.11683",tags:["computer vision","robot vision"],code:"https://ac-rad.github.io/MVTrans/",data:"https://ac-rad.github.io/MVTrans/",video:"https://www.youtube.com/watch?v=8Qdc_xWVp-k&ab_channel=XuHaoping",thumbnail:"/assets/publication-thumbnails/icra23-mvtrans.png",description:""},{bibtex:"\n      @article{https://doi.org/10.48550/arxiv.2212.09672,\n           author = {Naruki Yoshikawa and Andrew Zou Li and Kourosh Darvish and Yuchi Zhao and Haoping Xu and Alan Aspuru-Guzik and Animesh Garg and Florian Shkurti},\n           title = {Chemistry Lab Automation via Constrained Task and Motion Planning},\n           journal = {ArXiv},\n           year = {2022},\n           volume={abs/2212.09672}\n      }\n    ",html:"https://arxiv.org/abs/2212.09672",tags:["task and motion planning","planning","manipulation"],video:"https://ac-rad.github.io/arc-icra2023/",code:"https://ac-rad.github.io/arc-icra2023/",data:"https://ac-rad.github.io/arc-icra2023/",thumbnail:"/assets/publication-thumbnails/icra23-chemistry-tamp.gif",description:""},{bibtex:"\n      @inproceedings{xu2021seeing,\n        title={Seeing Glass: Joint Point-Cloud and Depth Completion for Transparent Objects},\n        author={Haoping Xu and Yi Ru Wang and Sagi Eppel and Alan Aspuru-Guzik and Florian Shkurti and Animesh Garg},\n        booktitle={Conference on Robot Learning (CoRL)},\n        year={2021},\n        url={https://openreview.net/forum?id=tCfLLiP7vje}\n      }\n    ",html:"https://openreview.net/forum?id=tCfLLiP7vje",tags:["robot vision"],video:"https://www.youtube.com/watch?v=SuUMKy52b4E&ab_channel=ConferenceonRobotLearning",code:"https://www.pair.toronto.edu/TranspareNet/",data:"https://borealisdata.ca/dataset.xhtml?persistentId=doi:10.5683/SP3/ZJJAJ3",thumbnail:"/assets/publication-thumbnails/todd.png",description:""},{bibtex:"\n      @inproceedings{agia2021taskography,\n         title={Taskography: Evaluating robot task planning over large 3D scene graphs},\n         author={Christopher Agia and Krishna Murthy Jatavallabhula and Mohamed Khodeir and Ondrej Miksik and Vibhav Vineet and Mustafa Mukadam and Liam Paull and Florian Shkurti},\n         booktitle={Conference on Robot Learning (CoRL)},\n         year={2021},\n         url={https://openreview.net/forum?id=nWLt35BU1z_}\n     }\n    ",html:"https://taskography.github.io/",tags:["planning"],video:"https://www.youtube.com/watch?v=mM4v5hP4LdA&t=17s&ab_channel=KrishnaMurthy",code:"https://github.com/taskography",thumbnail:"/assets/publication-thumbnails/taskography.png",description:""},{bibtex:"\n      @InProceedings{Khorasgani_2022_CVPR,\n    author    = {Salar Hosseini Khorasgani and Yuxuan Chen and Florian Shkurti},\n    title     = {SLIC: Self-Supervised Learning With Iterative Clustering for Human Action Videos},\n    booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n    month     = {June},\n    year      = {2022},\n    pages     = {16091-16101}\n    }\n    ",html:"https://openaccess.thecvf.com/content/CVPR2022/html/Khorasgani_SLIC_Self-Supervised_Learning_With_Iterative_Clustering_for_Human_Action_Videos_CVPR_2022_paper.html",tags:["computer vision"],video:"https://youtu.be/iTt4rOLdjCo",code:"https://github.com/rvl-lab-utoronto/video_similarity_search",thumbnail:"/assets/publication-thumbnails/slic.png",description:""},{bibtex:"\n      @inproceedings{equivariant_imitation_learning,\n        title={Augmenting Imitation Experience via Equivariant Representations},\n        author={Dhruv Sharma and Alihusein Kuwajerwala and Florian Shkurti},\n        year={2022},\n        pages={9383-9389},   \n        booktitle = {International Conference on Robotics and Automation (ICRA)}, \n      }\n    ",html:"https://arxiv.org/abs/2110.07668",tags:["robot vision","imitation learning"],video:"https://youtu.be/l-sCSj7PfmY",thumbnail:"/assets/publication-thumbnails/equivariant_imitation_sharma.png",description:""},{bibtex:"\n      @inproceedings{csc_homanga,\n        title={Conservative Safety Critics for Exploration},\n        author={Homanga Bharadhwaj and Aviral Kumar and Nicholas Rhinehart and Sergey Levine and Florian Shkurti and Animesh Garg},\n        year={2021},\n        booktitle = {International Conference on Learning Representations (ICLR)}, \n      }\n    ",html:"https://arxiv.org/abs/2010.14497",tags:["reinforcement learning","safe learning"],thumbnail:"/assets/publication-thumbnails/Conservative Safety Critics for Exploration.png",description:""},{bibtex:"\n      @inproceedings{gradsim,\n        title={gradSim: Differentiable simulation for system identification and visuomotor control },\n        author={Krishna Jatavallabhula and Miles Macklin and Florian Golemo and Vikram Voleti and Linda Petrini and Martin Weiss and Breandan Considine and Jerome Parent-Levesque and Kevin Xie and Kenny Erleben and Liam Paull and Florian Shkurti and Sanja Fidler and Derek Nowrouzezahrai},\n        year={2021},\n        booktitle = {International Conference on Learning Representations (ICLR)}, \n      }\n    ",html:"https://openreview.net/forum?id=c_E8kFWfhp0",tags:["simulation","differentiable rendering","system identification"],project:"https://gradsim.github.io/",thumbnail:"/assets/publication-thumbnails/gradSim Differentiable simulation for system identification and visuomotor control.png",description:""},{bibtex:"\n      @inproceedings{transferable_skills_kevin,\n        title={Skill Transfer via Partially Amortized Hierarchical Planning},\n        author={Kevin Xie and Homanga Bharadhwaj and Danijar Hafner and Animesh Garg and Florian Shkurti},\n        year={2021},\n        booktitle = {International Conference on Learning Representations (ICLR)},\n      }\n    ",html:"https://openreview.net/forum?id=jXe91kq3jAq",tags:["reinforcement learning"],thumbnail:"/assets/publication-thumbnails/Skill Transfer via Partially Amortized Hierarchical Planning.png",description:""},{bibtex:"\n      @inproceedings{sinha2020dibs,\n        title={DIBS: Diversity-Inducing Information Bottleneck in Model Ensembles},\n        author={Samarth Sinha and Homanga Bharadhwaj and Anirudh Goyal and Hugo Larochelle and Animesh Garg and Florian Shkurti},\n        year={2021},\n        booktitle = {Association for the Advancement of Artificial Intelligence (AAAI)}, \n      }\n    ",html:"https://arxiv.org/abs/2003.04514",tags:["ensemble methods"],thumbnail:"/assets/publication-thumbnails/DIBS Diversity-Inducing Information Bottleneck in Model Ensembles.png",description:""},{bibtex:"\n      @inproceedings{koreitem2020oneshot,\n        title={One-Shot Informed Robotic Visual Search in the Wild},\n        author={Karim Koreitem and Florian Shkurti and Travis Manderson and Wei-Di Chang and Juan Camilo Gamboa Higuera and Gregory Dudek},\n        year={2020},\n        eprint={2003.10010},\n        archivePrefix={arXiv},\n        primaryClass={cs.RO},\n        booktitle={IEEE International Conference on Intelligent Robots and Systems (IROS)},\n      }\n    ",html:"https://arxiv.org/abs/2003.10010",code:"https://github.com/rvl-lab-utoronto/visual_search_in_the_wild",tags:["field robotics","robot vision","human-robot interaction"],thumbnail:"/assets/publication-thumbnails/One-Shot Informed Robotic Visual Search in the Wild.png",description:""},{bibtex:"\n      @INPROCEEDINGS{Manderson-RSS-20, \n        AUTHOR    = {Travis Manderson AND Juan Camilo Gamboa Higuera AND Stefan Wapnick AND Jean-Fran\xe7ois Tremblay AND Florian Shkurti AND David Meger AND Gregory Dudek}, \n        TITLE     = {{Vision-Based Goal-Conditioned Policies for Underwater Navigation in the Presence of Obstacles}}, \n        BOOKTITLE = {Robotics: Science and Systems (RSS)}, \n        YEAR      = {2020}, \n        ADDRESS   = {Corvalis, Oregon, USA}, \n        MONTH     = {July}, \n        DOI       = {10.15607/RSS.2020.XVI.048},\n      } \n    ",html:"http://www.roboticsproceedings.org/rss16/p048.html",video:"https://www.youtube.com/watch?v=qpcmwb_7QA4",project:"http://www.cim.mcgill.ca/mrl/nav2goal/",tags:["field robotics","robot vision","imitation learning"],thumbnail:"/assets/publication-thumbnails/Vision-Based Goal-Conditioned Policies for Underwater Navigation in the Presence of Obstacles.png",description:""},{bibtex:"\n      @inproceedings{bharadhwaj2020leaf,\n        title={LEAF: Latent Exploration Along the Frontier},\n        author={Homanga Bharadhwaj and Animesh Garg and Florian Shkurti},\n        year={2021},\n        eprint={2005.10934},\n        archivePrefix={arXiv},\n        primaryClass={cs.RO},\n        booktitle={IEEE International Conference on Robotics and Automation (ICRA)},\n      }\n    ",project:"https://sites.google.com/view/leaf-exploration",html:"https://arxiv.org/abs/2005.10934",tags:["reinforcement learning"],thumbnail:"/assets/publication-thumbnails/LEAF Latent Exploration Along the Frontier.png",description:""},{bibtex:"\n      @inproceedings{yuchen_wu_il_rl,\n        title={Shaping Rewards for Reinforcement Learning with Imperfect Demonstrations using Generative Models},\n        author={Yuchen Wu and Melissa Mozifian and Florian Shkurti},\n        year={2021},\n        eprint={2011.01298},\n        archivePrefix={arXiv},\n        primaryClass={cs.RO},\n        booktitle={IEEE International Conference on Robotics and Automation (ICRA)},\n      }\n    ",html:"https://arxiv.org/abs/2011.01298",tags:["reinforcement learning","imitation learning"],thumbnail:"/assets/publication-thumbnails/Shaping Rewards for Reinforcement Learning with Imperfect Demonstrations using Generative Models.png",description:""},{bibtex:"\n      @inproceedings{hypercrl,\n        title={Continual Model-Based Reinforcement Learning with Hypernetworks},\n        author={Yizhou Huang and Kevin Xie and Homanga Bharadhwaj and Florian Shkurti},\n        year={2021},\n        eprint={2009.11997},\n        archivePrefix={arXiv},\n        primaryClass={cs.RO},\n        booktitle={IEEE International Conference on Robotics and Automation (ICRA)},\n      }\n    ",html:"https://arxiv.org/abs/2009.11997",tags:["reinforcement learning","continual learning"],thumbnail:"/assets/publication-thumbnails/Continual Model-Based Reinforcement Learning with Hypernetworks.png",description:""},{bibtex:"\n      @inproceedings{loho,\n        title={LOHO: Latent Optimization of Hairstyles via Orthogonalization},\n        author={Rohit Saha and Brendan Duke and Florian Shkurti and Graham Taylor and Parham Aarabi},\n        year={2021},\n        eprint={2103.03891},\n        archivePrefix={arXiv},\n        primaryClass={cs.CV},\n        booktitle={Computer Vision and Pattern Recognition (CVPR)},\n      }\n    ",html:"https://arxiv.org/abs/2103.03891",tags:["generative models","image synthesis"],thumbnail:"/assets/publication-thumbnails/LOHO Latent Optimization of Hairstyles via Orthogonalization.png",description:""},{bibtex:"\n      @inproceedings{dong2020catch,\n        title={Catch the Ball: Accurate High-Speed Motions for Mobile Manipulators via Inverse Dynamics Learning},\n        author={Ke Dong and Karime Pereida and Florian Shkurti and Angela P. Schoellig},\n        year={2020},\n        eprint={2003.07489},\n        archivePrefix={arXiv},\n        primaryClass={cs.RO},\n        booktitle={IEEE International Conference on Intelligent Robots and Systems (IROS)},\n      }\n    ",html:"https://arxiv.org/abs/2003.07489",video:"https://www.youtube.com/watch?v=4uCvzurthS4",tags:["manipulation","control"],thumbnail:"/assets/publication-thumbnails/Catch the Ball Accurate High-Speed Motions for Mobile Manipulators via Inverse Dynamics Learning.png",description:""},{bibtex:"\n      @inproceedings{bharadhwaj2020modelpredictive,\n        title={Model-Predictive Control via Cross-Entropy and Gradient-Based Optimization},\n        author={Homanga Bharadhwaj and Kevin Xie and Florian Shkurti},\n        year={2020},\n        eprint={2004.08763},\n        archivePrefix={arXiv},\n        primaryClass={cs.LG},\n        booktitle={Conference on Learning for Dynamics and Control (L4DC)},\n      }\n    ",html:"https://arxiv.org/abs/2004.08763",tags:["planning","reinforcement learning"],thumbnail:"/assets/publication-thumbnails/Model-Predictive Control via Cross-Entropy and Gradient-Based Optimization.png",description:""},{bibtex:"\n      @article{Abeysirigoonawardena2019GeneratingAD,\n        title={Generating Adversarial Driving Scenarios in High-Fidelity Simulators},\n        author={Yasasa Abeysirigoonawardena and Florian Shkurti and Gregory Dudek},\n        journal={International Conference on Robotics and Automation (ICRA)},\n        year={2019},\n        pages={8271-8277},\n      }\n    ",project:"http://cim.mcgill.ca/~mrl/adversarial_driving_scenarios/",tags:["simulation","adversarial scenarios"],thumbnail:"/assets/publication-thumbnails/Generating Adversarial Driving Scenarios in High-Fidelity Simulators.png",description:""},{bibtex:'\n      @InProceedings{ florianICRA2018,\n        author = {Shkurti, Florian and Kakodkar, Nikhil and Dudek, Gregory},\n        title = {{Model-Based Probabilistic Pursuit via Inverse Reinforcement Learning}},\n        booktitle = "IEEE International Conference on Robotics and Automation (ICRA)",\n        year = "2018",\n        pages = "7804-7811",\n        month = "May",\n        address = "Brisbane, Australia",\n      }\n    ',video:"http://www.cim.mcgill.ca/~florian/pursuit_via_irl.mp4",pdf:"assets/pdf/icra_2018_irl_pursuit.pdf",tags:["planning","imitation learning"],thumbnail:"/assets/publication-thumbnails/Model-Based Probabilistic Pursuit via Inverse Reinforcement Learning.png",description:""},{bibtex:"\n      @INPROCEEDINGS{koreitemoceans18, \n        author={Karim Koreitem and Jimmy Li and Ian Karp and Travis Manderson and Florian Shkurti and Gregory Dudek}, \n        booktitle={IEEE OCEANS}, \n        title={Synthetically Trained 3D Visual Tracker of Underwater Vehicles}, \n        year={2018}, \n        volume={}, \n        number={}, \n        pages={1-7}, \n        month={Oct},\n      }\n    ",pdf:"assets/pdf/oceans18_synthetic_tracking.pdf",tags:["robot vision","field robotics","simulation"],thumbnail:"/assets/publication-thumbnails/Synthetically Trained 3D Visual Tracker of Underwater Vehicles.png",description:""},{bibtex:'\n      @InProceedings{convoying_iros_2017,\n        author = {Shkurti, Florian and Chang, {Wei Di} and Henderson, Peter and Islam, {Md. Jahidul} and {Gamboa Higuera}, {Juan Camilo} and Li, Jimmy and Manderson, Travis and Xu, Anqi and Dudek, Gregory and Sattar, Junaed},\n        title = "Underwater Multi-Robot Convoying Using Visual Tracking by Detection",\n        booktitle = "IEEE International Conference on Intelligent Robots and Systems (IROS)",\n        pages = "4189--4196",\n        year = "2017",\n        month = "September",\n        address = "Vancouver, Canada",\n        video= "http://www.cim.mcgill.ca/~mrl/robot_tracking/",\n      }\n    ',pdf:"assets/pdf/iros17_visual_convoying.pdf",tags:["robot vision","field robotics"],thumbnail:"/assets/publication-thumbnails/Underwater Multi-Robot Convoying Using Visual Tracking by Detection.png",description:""},{bibtex:'\n      @InProceedings{topological_pursuit_iros_2017,\n        author = "Florian Shkurti and Gregory Dudek",\n        title = "Topologically distinct trajectory predictions for probabilistic pursuit",\n        booktitle = "IEEE International Conference on Intelligent Robots and Systems (IROS)",\n        pages = "5653--5660",\n        year = "2017",\n        month = "September",\n        address = "Vancouver, Canada",\n      }\n    ',pdf:"assets/pdf/iros17_topological_pursuit.pdf",tags:["planning"],thumbnail:"/assets/publication-thumbnails/Topologically distinct trajectory predictions for probabilistic pursuit.png",description:""},{bibtex:"\n      @article{benchmark_environments_multitask,\n        author    = {Peter Henderson and\n                    Wei{-}Di Chang and\n                    Florian Shkurti and\n                    Johanna Hansen and\n                    David Meger and\n                    Gregory Dudek},\n        title     = {Benchmark Environments for Multitask Learning in Continuous Domains},\n        journal   = {CoRR},\n        volume    = {abs/1708.04352},\n        year      = {2017},\n        archivePrefix = {arXiv},\n        eprint    = {1708.04352},\n      }\n    ",html:"https://arxiv.org/abs/1708.04352",tags:["reinforcement learning","simulation"],thumbnail:"/assets/publication-thumbnails/Benchmark Environments for Multitask Learning in Continuous Domains.png",description:""},{bibtex:"\n      @inproceedings{manderson_crv_2016,\n        Author = {Manderson, Travis and Shkurti, Florian and Dudek, Gregory},\n        Booktitle = {Conference on Computer and Robot Vision (CRV)},\n        Month = {May},\n        Publisher = {IEEE Computer Society},\n        Title = {Texture-Aware SLAM Using Stereo Imagery And Inertial Information},\n              Pages = {465--463},\n              Year = {2016},\n      }\n    ",pdf:"assets/pdf/crv_2016_texture_aware_slam.pdf",tags:["field robotics","estimation","robot vision"],thumbnail:"/assets/publication-thumbnails/Texture-Aware SLAM Using Stereo Imagery And Inertial Information.png",description:""},{bibtex:"\n      @inproceedings{iros2014_megerShkurtiCortesPozaGiguereDudek,\n        author = {David Meger and Florian Shkurti and David Cort'{e}s Poza and Philippe Gigu`{e}re and Gregory Dudek},\n        title = {3D Trajectory Synthesis and Control for a Legged Swimming Robot},\n        booktitle = {Proceedings of the IEEE International Conference on Robotics and Intelligent Systems (IROS)},\n        year = {2014},\n      }\n    ",pdf:"assets/pdf/iros2014_3d_autopilot.pdf",project:"http://www.cim.mcgill.ca/~dmeger/IROS2014_3DTrajectories/",tags:["field robotics","control"],thumbnail:"/assets/publication-thumbnails/3D Trajectory Synthesis and Control for a Legged Swimming Robot.png",description:""},{bibtex:'\n      @InProceedings{Qiwen14iros,\n        author = {Zhang, Qiwen and Whitney, David and Shkurti, Florian and Rekleitis, Ioannis},\n        title = {{Ear-based Exploration on Hybrid Metric/Topological Maps}},\n        booktitle = "IEEE International Conference on Intelligent Robots and Systems (IROS)",\n        pages = "3081--3088",\n        year = "2014",\n        month = "September",\n        address = "Chicago, USA",\n\n      }\n    ',pdf:"assets/pdf/iros2014_gvg.pdf",tags:["planning"],thumbnail:"/assets/publication-thumbnails/Ear-based Exploration on Hybrid MetricTopological Maps.png",description:""},{bibtex:"\n      @inproceedings{Meghjani:2014:ARS:2623380.2623579,\n        author = {Meghjani, Malika and Shkurti, Florian and Higuera, Juan Camilo Gamboa and Kalmbach, Arnold and Whitney, David and Dudek, Gregory},\n        title = {Asymmetric Rendezvous Search at Sea},\n        booktitle = {Conference on Computer and Robot Vision (CRV)},\n        year = {2014},\n        pages = {175--180},\n      }\n    ",pdf:"assets/pdf/crv2014_asymmetric_rendezvous.pdf",tags:["field robotics","planning","control"],thumbnail:"/assets/publication-thumbnails/Asymmetric Rendezvous Search at Sea.png",description:""},{bibtex:'\n      @InProceedings{ Florian2014MaxViz,\n        author = {Shkurti, Florian and Dudek, Gregory},\n        title = {{Maximizing Visibility in Collaborative Trajectory Planning}},\n        booktitle = "IEEE International Conference on Robotics and Automation (ICRA)",\n        pages = "3771-3776",\n        year = "2014",\n        month = "May",\n        address = "Hong Kong",\n      }\n    ',pdf:"assets/pdf/icra2014_max_viz_planning.pdf",tags:["planning"],thumbnail:"/assets/publication-thumbnails/Maximizing Visibility in Collaborative Trajectory Planning.png",description:""},{bibtex:'\n      @InProceedings{Shkurti13icra,\n        author = {Shkurti, Florian and Dudek, Gregory},\n        title = {{On the Complexity of Searching for an Evader with a Faster Pursuer}},\n        booktitle = "IEEE International Conference on Robotics and Automation (ICRA)",\n        pages = "4047--4052",\n        year = "2013",\n        month = "May",\n        address = "Karlsruhe, Germany",\n      }\n    ',pdf:"assets/pdf/icra2013_complexity_pursuit_evasion.pdf",tags:["planning"],thumbnail:"/assets/publication-thumbnails/On the Complexity of Searching for an Evader with a Faster Pursuer.png",description:""},{bibtex:'\n      @InProceedings{Shkurti12iros,\n        author = {Shkurti, Florian and Xu, Anqi and Meghjani, Malika and {Gamboa Higuera}, {Juan Camilo} and  Girdhar, Yogesh and Giguere, Philippe and Dey, {Bir Bikram} and Li, Jimmy and Kalmbach, Arnold and Prahacs, Chris and Turgeon, Katrine and Rekleitis, Ioannis and Dudek, Gregory},\n        title = {{Multi-Domain Monitoring of Marine Environments Using a Heterogeneous Robot Team}},\n        booktitle = "IEEE International Conference on Intelligent Robots and Systems (IROS)",\n        pages = "1747--1753",\n        year = "2012",\n        month = "October",\n        address = "Algarve, Portugal",              \n      }\n    ',pdf:"assets/pdf/iros2012_multirobot_env_monitoring.pdf",project:"http://www.cim.mcgill.ca/~mrl/multi_robot_env_monitoring/",video:"https://www.youtube.com/watch?time_continue=1&v=DvWVC5R0zqs",tags:["field robotics"],thumbnail:"/assets/publication-thumbnails/Multi-Domain Monitoring of Marine Environments Using a Heterogeneous Robot Team.png",description:""},{bibtex:"\n      @InProceedings{ Gamboa2012SocialPlan,\n        author = {Juan Camilo Gamboa Higuera and Anqi Xu and Florian Shkurti and Gregory Dudek},\n        title = {Socially-Driven Collective Path Planning for Robot Missions},\n        booktitle = {Conference on Computer and Robot Vision (CRV)},\n        year = {2012},\n        pages = {417--424},\n        address = {Toronto, Canada},\n        month = {May},\n      }\n    ",pdf:"assets/pdf/crv2012_social_plan.pdf",tags:["planning"],thumbnail:"/assets/publication-thumbnails/Socially-Driven Collective Path Planning for Robot Missions.png",description:""},{bibtex:'\n      @InProceedings{florian_state_est,\n        author = {Shkurti, Florian and Rekleitis, Ioannis and Scaccia, Milena and Dudek, Gregory},\n        title = "{State estimation of an underwater robot using visual and inertial information}",\n        booktitle = "IEEE International Conference on Intelligent Robots and Systems (IROS)",\n        pages = "5054--5060",\n        year = "2011",\n        month = "September",\n        address = "San Francisco, USA",\n      }\n    ',pdf:"assets/pdf/iros_2011_state_est.pdf",tags:["estimation","field robotics"],thumbnail:"/assets/publication-thumbnails/State estimation of an underwater robot using visual and inertial information.png",description:""},{bibtex:'\n      @InProceedings{ Girdhar2011MARE,\n        author = "Yogesh Girdhar and Anqi Xu and Bir Bikram Dey and Malika Meghjani and Florian Shkurti and Ioannis Rekleitis and Gregory Dudek",\n        title = "{MARE: Marine Autonomous Robotic Explorer}",\n        booktitle = "IEEE International Conference on Intelligent Robots and Systems (IROS)",\n        pages = "5048--5053",\n        year = "2011",\n        month = "September",\n        address = "San Francisco, USA",\n      }\n    ',pdf:"assets/pdf/iros2011_boat.pdf",tags:["field robotics","robot vision"],thumbnail:"/assets/publication-thumbnails/MARE Marine Autonomous Robotic Explorer.png",description:""},{bibtex:"\n      @inproceedings{florian_crv_2011,\n        Author = {Shkurti, Florian and Rekleitis, Ioannis and Dudek, Gregory},\n        Booktitle = {Conference on Computer and Robot Vision},\n        Month = {May},\n        Publisher = {IEEE Computer Society},\n        Title = {Feature Tracking Evaluation for Pose Estimation in Underwater Environments},\n              Pages = {160--167},\n              Year = {2011},\n      }\n    ",pdf:"assets/pdf/crv2011_underwater_ft.pdf",tags:["field robotics","robot vision"],thumbnail:"/assets/publication-thumbnails/Feature Tracking Evaluation for Pose Estimation in Underwater Environments.png",description:""}],be=(n(375),n(99));function me(e){var t={pdf:"pdf",html:"pdf",bibtex:"bibtex",video:"video",project:"project",code:"code"},n=Object(be.a)(),a=n.getCollapseProps,i=n.getToggleProps,o=Object(g.jsx)(g.Fragment,{});return void 0!==e.publication.pdf&&void 0!==e.publication.thumbnail?o=Object(g.jsx)("a",{href:"/rvl-lab-utoronto.github.io/"+e.publication.pdf,children:Object(g.jsx)("img",{className:"publication-thumbnail",alt:e.publication.title,src:"/rvl-lab-utoronto.github.io/"+e.publication.thumbnail})}):void 0!==e.publication.html&&void 0!==e.publication.thumbnail?o=Object(g.jsx)("a",{href:e.publication.html,children:Object(g.jsx)("img",{className:"publication-thumbnail",alt:e.publication.title,src:"/rvl-lab-utoronto.github.io/"+e.publication.thumbnail})}):void 0!==e.publication.thumbnail&&(o=Object(g.jsx)("img",{className:"publication-thumbnail",alt:e.publication.title,src:"/rvl-lab-utoronto.github.io/"+e.publication.thumbnail})),Object(g.jsxs)("div",{className:"publication-entry",children:[e.showYear?Object(g.jsxs)(g.Fragment,{children:[Object(g.jsx)("hr",{}),Object(g.jsx)("h2",{children:e.publication.year})]}):Object(g.jsx)("div",{}),Object(g.jsxs)("div",{style:{display:"flex",flexDirection:"row",alignItems:"center"},children:[Object(g.jsx)("div",{className:"desktop-view",children:Object(g.jsx)("div",{style:{paddingRight:"25px"},children:o})}),Object(g.jsxs)("div",{children:[Object(g.jsx)("h3",{children:e.publication.title}),Object(g.jsx)("p",{children:e.publication.author}),""!==e.publication.booktitle?Object(g.jsx)("p",{children:Object(g.jsx)("span",{children:e.publication.booktitle})}):Object(g.jsx)("div",{}),""!==e.publication.journal?Object(g.jsx)("p",{children:Object(g.jsx)("span",{children:e.publication.journal})}):Object(g.jsx)("div",{}),void 0!==e.publication.tags?Object(g.jsx)("div",{children:e.publication.tags.map((function(t){return Object(g.jsx)(ge,{tag:t,selected:e.selectedTags.includes(t),addSelectedTag:e.addSelectedTag,removeSelectedTag:e.removeSelectedTag})}))}):Object(g.jsx)("div",{}),Object(g.jsx)("div",{style:{marginLeft:"-3px",marginTop:"3px"},children:Object.keys(t).map((function(n){return void 0!==e.publication[n]&&""!==e.publication[n]?"bibtex"===n?Object(g.jsxs)("div",Object(he.a)(Object(he.a)({style:{display:"inline",marginLeft:"3px"}},i()),{},{children:["[",Object(g.jsx)("div",{className:"a",style:{display:"inline"},children:"bibtex"}),"]"]}),n):"pdf"===n?Object(g.jsxs)("div",{style:{display:"inline",marginLeft:"3px"},children:["[",Object(g.jsx)("a",{href:"/rvl-lab-utoronto.github.io/"+e.publication[n],children:t[n]}),"]"]},n):Object(g.jsxs)("div",{style:{display:"inline",marginLeft:"3px"},children:["[",Object(g.jsx)("a",{href:e.publication[n],children:t[n]}),"]"]},n):Object(g.jsx)(g.Fragment,{})}))}),Object(g.jsx)("div",Object(he.a)(Object(he.a)({},a()),{},{children:Object(g.jsx)("div",{className:"bibtex-expand",children:e.publication.bibtex})}))]})]})]})}var ge=function(e){Object(b.a)(n,e);var t=Object(m.a)(n);function n(e){var a,i;return Object(p.a)(this,n),(i=t.call(this,e)).onClick=function(){i.state.selected?i.props.removeSelectedTag(i.props.tag):i.props.addSelectedTag(i.props.tag),i.setState({selected:!i.state.selected})},i.state={selected:null!==(a=i.props.selected)&&void 0!==a&&a},i}return Object(u.a)(n,[{key:"componentDidUpdate",value:function(e){this.props.selected!==e.selected&&this.setState({selected:this.props.selected})}},{key:"render",value:function(){return Object(g.jsx)("div",{onClick:this.onClick,className:"publication-tag "+(this.state.selected?"publication-tag-selected":""),children:this.props.tag})}}]),n}(a.Component),je=(n(378),function(e){Object(b.a)(n,e);var t=Object(m.a)(n);function n(){return Object(p.a)(this,n),t.apply(this,arguments)}return Object(u.a)(n,[{key:"render",value:function(){return Object(g.jsxs)(g.Fragment,{children:[Object(g.jsx)("h1",{className:"page-header",children:this.props.title}),this.props.children,!1===this.props.showBreak?Object(g.jsx)("div",{}):Object(g.jsx)("hr",{})]})}}]),n}(a.Component)),ve=n(100),fe=n.n(ve);function xe(e){if(!e.toLowerCase().includes(" and "))return e;for(var t=e.split(/ and /gi),n="",a=0;a<t.length;a++)n=a===t.length-1?n+" and "+t[a]:n+t[a]+", ";return n}function Oe(e){for(var t=e,n=(t=(t=(t=(t=(t=(t=(t=(t=(t=t.replaceAll("{{","{")).replaceAll("}}","}")).replace(/\s+/g," ")).replaceAll(" = ","=")).replaceAll(" =","=")).replaceAll("= ","=")).replaceAll('"{',"{")).replaceAll('}"',"}")).replaceAll("\n","")).toLowerCase(),a=["title","author","year","booktitle","journal"],i=0;i<a.length;i++){var o=", "+a[i]+"={",s=n.indexOf(o),r=n.indexOf(o)+o.length;-1!==s&&(t=t.replace(t.substring(s,r),t.substring(s,r).toLowerCase()))}return t}var ye=n(383),ke=function(e){Object(b.a)(n,e);var t=Object(m.a)(n);function n(e){var a;return Object(p.a)(this,n),(a=t.call(this,e)).filterPublications=function(){if(""===a.searchTerm&&0===a.selectedTags.length)return a.setState({shownPublications:a.state.publications}),void a.props.history.push({search:"?"+new URLSearchParams({}).toString()});0!==a.selectedTags.length&&""===a.searchTerm?a.props.history.push({search:"?"+new URLSearchParams({tags:JSON.stringify(a.selectedTags)}).toString()}):0===a.selectedTags.length&&""!==a.searchTerm?a.props.history.push({search:"?"+new URLSearchParams({search:JSON.stringify(a.searchTerm)}).toString()}):a.props.history.push({search:"?"+new URLSearchParams({tags:JSON.stringify(a.selectedTags),search:JSON.stringify(a.searchTerm)}).toString()});for(var e=a.state.publications,t=[],n=!1,i=0;i<e.length;i++){n=!1;for(var o=0;o<e[i].tags.length&&((a.selectedTags.includes(e[i].tags[o])||0===a.selectedTags.length)&&(""===a.searchTerm||e[i].title.toLowerCase().includes(a.searchTerm.toLowerCase())||e[i].author.toLowerCase().includes(a.searchTerm.toLowerCase())||e[i].booktitle.toLowerCase().includes(a.searchTerm.toLowerCase())||e[i].journal.toLowerCase().includes(a.searchTerm.toLowerCase()))&&(t.push(e[i]),n=!0),!n);o++);}a.setState({shownPublications:t})},a.getAllTags=function(e){for(var t=[],n=0;n<e.length;n++)if(void 0!==e[n].tags)for(var a=0;a<e[n].tags.length;a++)t.includes(e[n].tags[a])||t.push(e[n].tags[a]);return t.sort((function(e,t){var n=e.toUpperCase(),a=t.toUpperCase();return n<a?-1:n>a?1:0})),t},a.addSelectedTag=function(e){a.selectedTags.push(e),a.filterPublications()},a.removeSelectedTag=function(e){var t=Object(r.a)(a.selectedTags),n=t.indexOf(e);-1!==n&&(t.splice(n,1),a.selectedTags=t,a.filterPublications())},a.searchTerm="",a.selectedTags=[],a.state={publications:[],shownPublications:[],allTags:[]},a}return Object(u.a)(n,[{key:"componentDidMount",value:function(){var e=Object(y.a)(x.a.mark((function e(){var t,n,a,i,o,s,r,c,l,d,h,p,u,b,m,g,j=this;return x.a.wrap((function(e){for(;;)switch(e.prev=e.next){case 0:for(t=[],n=0;n<ue.length;n++)u=ue[n],b=ye.toJSON(Oe(ue[n].bibtex))[0],u.title=null!==(a=null===(i=b.entryTags)||void 0===i?void 0:i.title)&&void 0!==a?a:"",u.author=xe(null!==(o=null===(s=b.entryTags)||void 0===s?void 0:s.author)&&void 0!==o?o:""),u.year=null!==(r=null===(c=b.entryTags)||void 0===c?void 0:c.year)&&void 0!==r?r:"",u.booktitle=null!==(l=null===(d=b.entryTags)||void 0===d?void 0:d.booktitle)&&void 0!==l?l:"",u.journal=null!==(h=null===(p=b.entryTags)||void 0===p?void 0:p.journal)&&void 0!==h?h:"",t.push(u);t.sort((function(e,t){var n=e.booktitle.toUpperCase(),a=t.booktitle.toUpperCase();return n>a?-1:n<a?1:0})),t.sort((function(e,t){var n=e.year.toUpperCase(),a=t.year.toUpperCase();return n>a?-1:n<a?1:0})),m=this.getAllTags(t),this.setState({publications:t,shownPublications:t,allTags:m}),void 0===(g=fe.a.parse(this.props.location.search)).tags&&void 0===g.search||(console.log(JSON.parse(g.tags)),void 0!==g.tags?this.selectedTags=JSON.parse(g.tags):this.selectedTags=[],void 0!==g.search?this.searchTerm=JSON.parse(g.search):this.searchTerm="",setTimeout((function(){j.filterPublications()}),1));case 8:case"end":return e.stop()}}),e,this)})));return function(){return e.apply(this,arguments)}}()},{key:"render",value:function(){var e=this,t="";return Object(g.jsx)(g.Fragment,{children:Object(g.jsx)("div",{className:"center",children:Object(g.jsxs)("div",{className:"horizontal-padding max-width",children:[Object(g.jsxs)(je,{showBreak:!1,title:"Publications",children:[Object(g.jsx)("div",{style:{marginRight:"30px"},children:Object(g.jsx)(pe,{value:this.searchTerm,onChange:function(t){e.searchTerm=t,e.filterPublications()},placeholder:"Search title, author name, or publication venue"})}),void 0!==this.state.allTags?Object(g.jsx)("div",{children:this.state.allTags.map((function(t){return Object(g.jsx)(ge,{tag:t,addSelectedTag:e.addSelectedTag,removeSelectedTag:e.removeSelectedTag,selected:e.selectedTags.includes(t)})}))}):Object(g.jsx)("div",{})]}),this.state.shownPublications.map((function(n,a){return n.year!==t?(t=n.year,Object(g.jsx)(g.Fragment,{children:Object(g.jsx)(me,{showYear:!0,publication:n,selectedTags:e.selectedTags,addSelectedTag:e.addSelectedTag,removeSelectedTag:e.removeSelectedTag},a)})):Object(g.jsx)(g.Fragment,{children:Object(g.jsx)(me,{publication:n,selectedTags:e.selectedTags,addSelectedTag:e.addSelectedTag,removeSelectedTag:e.removeSelectedTag},a)})}))]})})})}}]),n}(a.Component),we=Object(l.g)(ke),Se={faculty:[{name:"Florian Shkurti",image:"assets/team/florian.jpg",description:"robot vision, machine learning, planning and control",website:"http://www.cs.toronto.edu/~florian/",twitter:"https://twitter.com/florian_shkurti",googleScholar:"https://scholar.google.com/citations?user=BDmtLHsAAAAJ&hl=en"}],Postdocs:[{name:"Kourosh Darvish",image:"assets/team/kourosh_darvish_2.jpg",description:"robotics, control, task and motion planning, machine learning, chemistry lab automation. co-supervised by <a href='https://animesh.garg.tech/'>Animesh Garg</a>",website:"https://kouroshd.github.io/",email:"kdarvish@cs.toronto.edu",linkedIn:"https://it.linkedin.com/in/kouroshdarvish",googleScholar:"https://scholar.google.com/citations?user=FwFFVdIAAAAJ"}],"PhD students":[{name:"Kevin Xie",image:"assets/team/kevin.jpg",description:"reinforcement learning, control, 3D vision. co-supervised by <a href='https://www.cs.utoronto.ca/~fidler/'>Sanja Fidler</a>",website:"https://kevincxie.github.io/",email:"kevincxie@cs.toronto.edu"},{name:"Qiao Gu",image:"assets/team/qiaogu.png",website:"https://georgegu1997.github.io/",email:"qiaog@andrew.cmu.edu",googleScholar:"https://scholar.google.com/citations?user=MF7ISVAAAAAJ&hl=en",description:"continual learning, computer vision"},{name:"Skylar Hao",image:"assets/team/skylar.png",description:"sim-to-real transfer, safe learning, statistics, machine learning"},{name:"Wei-Cheng Tseng",image:"assets/team/weicheng_tseng_1.jpg",description:"multi-agent reinforcement learning, computer vision",website:"https://weichengtseng.github.io/"},{name:"Sepehr Samavi",image:"assets/team/sepehr_samavi_1.jpg",description:"safe visual navigation. co-supervised by <a href='https://www.dynsyslab.org/prof-angela-schoellig/'>Angela Schoellig</a>",website:"http://dsl.utias.utoronto.ca/~sep/"}],"MSc students":[{name:"Anthony Lem",image:"assets/team/anthony_lem_1.jpg",description:"human pose detection and prediction",email:"anthony.lem@mail.utoronto.ca"},{name:"Mohamed Khodeir",image:"assets/team/mk.png",linkedIn:"https://ca.linkedin.com/in/khodeir",description:"learning to plan, task and motion planning"},{name:"Andrei Ivanovic",image:"assets/team/andrei_ivanovic_2.jpeg",description:"trajectory prediction and planning. co-supervised by <a href='https://www.gilitschenski.org/igor/'>Igor Gilitschenski</a>",linkedIn:"https://ca.linkedin.com/in/andrei-ivanovic-438313178"},{name:"Yewon Lee",image:"assets/team/yewon_lee_1.jpeg",description:"task and motion planning",website:"https://yewon-lee.github.io/",email:"yewonlee@cs.toronto.edu"},{name:"Yasasa Abeysirigoonawardena",image:"assets/team/profile.png",description:"adversarial scenario generation, neural rendering",linkedIn:"https://ca.linkedin.com/in/yasasa-abeysirigoonawardena-819229198"},{name:"Jinbang Huang",image:"assets/team/profile.png",description:"task and motion planning, control theory, optimization. co-supervised by <a href='http://stars.utias.utoronto.ca/~jkelly/'>Jonathan Kelly</a>",linkedIn:"https://ca.linkedin.com/in/jinbang-huang-989526170"}],"undergraduate students":[{name:"Hamza Dugmag",image:"assets/team/hamza_dugmag_1.jpg",description:"field robotics, autonomous boat",website:"https://hamzadugmag.com/"},{name:"Jisu Qian",image:"assets/team/jisu_qian_1.jpeg",description:"system identification",linkedIn:"https://ca.linkedin.com/in/jisu-qian-85b18921b"},{name:"Andrew Zou Li",image:"assets/team/andrew_z_li.jpg",description:"task and motion planning, chemistry lab automation",website:"https://andrewzl.github.io/",linkedIn:"https://www.linkedin.com/in/andrewzouli/"},{name:"Yuchi(Allan) Zhao",image:"assets/team/yuchi_allan_zhao_1.jpg",description:"robot manipulation, transparent object pose estimation, task and motion planning, chemistry lab automation",website:"https://y556zhao.github.io/",linkedIn:"https://www.linkedin.com/in/yuchi-allan-zhao/"}],alumni:[{name:"Haozhe Sheng",image:"assets/team/profile.png",description:"<b>next: Google</b>"},{name:"Julia Chae",image:"assets/team/julia_chae_1.jpg",description:"LiDAR and RGB representation learning <b>next: MIT EECS PhD</b>",linkedIn:"https://ca.linkedin.com/in/julia-chae",website:"https://juliachae.github.io/"},{name:"Philip Huang",image:"assets/team/philip.jpg",description:"continual learning, field robotics, task and motion planning. co-supervised by <a href='http://asrl.utias.utoronto.ca/~tdb/'>Tim Barfoot</a>. <b>next: CMU CS PhD</b>",linkedIn:"https://ca.linkedin.com/in/philip-yizhou-huang",website:"https://philip-huang.github.io/",googleScholar:"https://scholar.google.com/citations?hl=en&user=YDCsS5EAAAAJ"},{name:"Ben Agro",image:"assets/team/ben_agro.jpg",description:"learning to plan, task and motion planning, manipulation. <b>next: UofT CS PhD / Waabi</b>",website:"https://benagro314.github.io/",twitter:"https://twitter.com/BenAgro4",email:"ben.agro@mail.utoronto.ca"},{name:"Aditya Saigal",image:"assets/team/profile.png",linkedIn:"https://ca.linkedin.com/in/aditya-saigal-221207143?trk=pub-pbmap",description:"continual reinforcement learning"},{name:"Salar Hosseini",image:"assets/team/salar.jpg",description:"computer vision, adversarial scenario generation. <b>next: Samsung AI</b>",linkedIn:"https://ca.linkedin.com/in/salar-hosseini",website:"https://salarios77.github.io/",googleScholar:"https://scholar.google.ca/citations?user=8OT5mY0AAAAJ&hl=en"},{name:"Cathlyn Chen",image:"assets/team/cathlyn_chen_1.jpg",description:"backwards reachability for nonlinear systems",link:""},{name:"Alex Alexiev",image:"assets/team/alex_alexiev_1.jpeg",description:"task and motion planning",linkedIn:"https://alex-alexiev.github.io/"},{name:"Kathy Zhuang",image:"assets/team/kathy_zhuang_1.jpeg",description:"computer vision for transparent objects. <b>next: Berkeley CS MSc</b>",linkedIn:"https://ca.linkedin.com/in/yue-kathy-zhuang",website:"https://kathyzhuang.github.io/"},{name:"Artur Kuramshin",image:"assets/team/artur_kuramshin_1.jpeg",description:"field robotics, autonomous boat",website:"http://akuramshin.ca",email:"artur.kuramshin@mail.utoronto.ca",linkedIn:"https://www.linkedin.com/in/artur-kuramshin-4b926616a/"},{name:"Ruiqi Wang",image:"assets/team/ruiqi_wang_1.jpeg",description:"adversarial scenario generation. <b>next: Stanford CS MSc</b>",linkedIn:"https://www.linkedin.com/in/ruiqi-wang-3b970b150/"},{name:"Charlotte Zhang",image:"assets/team/profile.png",description:"field robotics, autonomous boat"},{name:"Jason Tang",image:"assets/team/profile.png",description:"continual image classification. <b>next: UofT CS MSc</b>"},{name:"Pranit Chawla",image:"assets/team/pranit_chawla_1.jpg",description:"LiDAR and RGB representation for imitation learning. <b>next: CMU CS MSc</b>",website:"https://www.pranitchawla.com/",linkedIn:"https://www.linkedin.com/in/pranit-chawla-503237145/"},{name:"Cong Wei",image:"assets/team/cong_wei_1.jpeg",linkedIn:"https://ca.linkedin.com/in/cong-wei-30",description:"video summarization, generative models <b>next: Waterloo CS PhD</b>"},{name:"Kamran Ramji",image:"assets/team/kamran_ramji_1.jpg",description:"combining imitation and reinforcement learning. <b>next: Apple</b>",linkedIn:"https://ca.linkedin.com/in/kamran-ramji"},{name:"Stephen Zhao",image:"assets/team/stephen_zhao_1.jpeg",description:"multi-agent reinforcement learning. co-supervised by <a href='http://www.cs.toronto.edu/~yangxu/'>Yang Xu</a>. <b>next: UofT CS MSc</b>",linkedIn:"https://ca.linkedin.com/in/zhaostephen"},{name:"Ke Dong",image:"assets/team/ke_dong_1.jpg",description:"control theory, learning for control, robotics, sim-to-real transfer. co-supervised by <a href='https://www.dynsyslab.org/prof-angela-schoellig/'>Angela Schoellig</a>. <b>next: Tencent AI</b>",linkedIn:"https://ca.linkedin.com/in/ke-dong-7a33a9171"},{name:"Dhruv Sharma",image:"assets/team/dhruv_sharma_1.png",description:"autonomous driving, robotics, computer vision. <b>next: Huawei</b>",linkedIn:"https://ca.linkedin.com/in/dhruvsharmauw",website:"https://sharmadhruv.weebly.com/",email:"dhruv.sharma@uwaterloo.ca"},{name:"Sherry Chen",image:"assets/team/sherry_chen_1.jpg",description:"video representation learning. <b>next: UTIAS MSc</b>",linkedIn:"https://ca.linkedin.com/in/sherry-chen-engsci127"},{name:"Sally Chen",image:"assets/team/sally_chen_1.jpg",description:"differentiable rendering for self-driving simulators. <b>next: CMU CS MSc</b>",linkedIn:"https://ca.linkedin.com/in/chuhan-chen"},{name:"Homanga Bharadhwaj",image:"assets/team/homanga_bharadhwaj_1.png",description:"reinforcement learning, safe exploration, robotics, recommender systems. co-supervised by <a href='https://animesh.garg.tech/'>Animesh Garg</a>. <b>next: CMU CS PhD</b>",website:"https://homangab.github.io/",email:"homangablackhole36@gmail.com",googleScholar:"https://scholar.google.ca/citations?user=wwW4HRQAAAAJ&hl=en",twitter:"https://twitter.com/mangahomanga"},{name:"Chris Agia",image:"assets/team/chris_agia_1.jpg",description:"3d vision for autonomous driving. <b>next: Stanford CS PhD</b>",website:"https://agiachris.github.io/",email:"cagia@stanford.edu",linkedIn:"https://www.linkedin.com/in/agiachris/"},{name:"Ali Kuwajerwala",image:"assets/team/ali_kuwajerwala_1.jpg",description:"backwards reachability for nonlinear systems. <b>next: MILA MSc</b>",linkedIn:"https://ca.linkedin.com/in/alikuwajerwala"},{name:"Melissa Mozifian",image:"assets/team/melissa_mozifian_1.jpg",description:"visiting phd student, McGill/MILA. combining imitation and reinforcement learning. <b>visitor: MILA, McGill</b>",website:"https://melfm.github.io/about.html",googleScholar:"https://scholar.google.com/citations?user=sygJEU0AAAAJ&hl=en"},{name:"Shichen Lu",image:"assets/team/shichen_lu_1.jpeg",description:"control and reinforcement learning for mobile manipulation. <b>next: UTIAS MSc</b",linkedIn:"https://ca.linkedin.com/in/shichen-lu"},{name:"Siyun Li",image:"assets/team/profile.png",description:"adversarial examples for self-driving simulators. <b>next: Stanford CS MSc</b>",linkedIn:"https://ca.linkedin.com/in/siyun-li"},{name:"Yuchen Wu",image:"assets/team/yuchen_wu_1.jpg",description:"combining imitation and reinforcement learning. <b>next: UTIAS MSc</b>",linkedIn:"https://ca.linkedin.com/in/yuchen-wu-a9838a14a"},{name:"Zidong Weng",image:"assets/team/profile.png",description:"out-of-distribution detection for image and lidar data. <b>next: Intel</b>",linkedIn:"https://ca.linkedin.com/in/zidong-weng-232035134"},{name:"Zihan Wang",image:"assets/team/zihan_wang_1.jpg",description:"imitation learning for robotics. <b>next: Stanford CS MSc</b>",website:"https://avinwangzh.github.io/Personal-Website/",email:"avin.wangzihan@gmail.com",linkedIn:"https://ca.linkedin.com/in/zihan-wang-70aa47ab"}]},Ce=(n(384),function(e){Object(b.a)(n,e);var t=Object(m.a)(n);function n(){return Object(p.a)(this,n),t.apply(this,arguments)}return Object(u.a)(n,[{key:"render",value:function(){var e=this,t=Object(g.jsx)("div",{className:"team-member-box",children:Object(g.jsxs)("div",{style:{display:"flex",flexDirection:"row"},children:[Object(g.jsx)("div",{children:Object(g.jsx)("img",{alt:this.props.teamMember.name,className:"team-member-image",src:"/rvl-lab-utoronto.github.io/"+this.props.teamMember.image})}),Object(g.jsxs)("div",{style:{display:"flex",flexDirection:"column",justifyContent:"center"},children:[Object(g.jsx)("h3",{className:"team-member-title",children:this.props.teamMember.name}),this.props.teamMember.description?Object(g.jsx)("p",{dangerouslySetInnerHTML:{__html:this.props.teamMember.description}}):Object(g.jsx)(g.Fragment,{}),Object(g.jsx)("div",{className:"team-member-socials",children:["website","email","twitter","linkedIn","googleScholar"].map((function(t){return void 0!==e.props.teamMember[t]?Object(g.jsx)(Ie,{social:t,teamMember:e.props.teamMember}):Object(g.jsx)(g.Fragment,{})}))})]})]})});return void 0!==this.props.teamMember.link&&""!==this.props.teamMember.link?Object(g.jsx)("a",{href:this.props.teamMember.link,className:"no-decoration",children:t}):Object(g.jsx)("div",{className:"no-hover",children:t})}}]),n}(a.Component)),Ie=function(e){Object(b.a)(n,e);var t=Object(m.a)(n);function n(){return Object(p.a)(this,n),t.apply(this,arguments)}return Object(u.a)(n,[{key:"render",value:function(){return Object(g.jsx)("a",{href:("email"===this.props.social?"mailto:":"")+this.props.teamMember[this.props.social],children:Object(g.jsx)("img",{className:"team-member-social-icon",alt:this.props.social,src:Ae(this.props.social)})})}}]),n}(a.Component);function Ae(e){switch(e){case"website":default:return n(85).default;case"email":return n(385).default;case"twitter":return n(386).default;case"linkedIn":return n(387).default;case"googleScholar":return n(388).default}}var _e={default:3,1250:2,950:1},Re=function(e){Object(b.a)(n,e);var t=Object(m.a)(n);function n(){return Object(p.a)(this,n),t.apply(this,arguments)}return Object(u.a)(n,[{key:"render",value:function(){for(var e=Object.keys(Se),t=[],n=0;n<e.length;n++)t.push("title"),t.push(e[n]);return Object(g.jsx)("div",{className:"center",children:Object(g.jsxs)("div",{className:"horizontal-padding max-width",children:[Object(g.jsx)("div",{style:{height:"10px"}}),t.map((function(e,n){return"title"===e?Object(g.jsx)("h2",{style:{marginBottom:"5px",marginTop:"10px",textTransform:"capitalize"},children:t[n+1]},e):Object(g.jsx)(g.Fragment,{children:Object(g.jsx)(ce.a,{breakpointCols:_e,className:"masonry-grid",children:Se[e].map((function(e){return Object(g.jsx)(Ce,{teamMember:e},e.name)}))},e)})}))]})})}}]),n}(a.Component),Te={main:[{title:"Home",link:"/",component:Object(g.jsx)(ne,{})},{title:"Publications",link:"/publications",component:Object(g.jsx)(we,{})},{title:"Team",link:"/team",component:Object(g.jsx)(Re,{})},{title:"Research",link:"/research",component:Object(g.jsx)(de,{})},{title:"Joining",link:"/joining",component:Object(g.jsx)(ie,{})},{title:"Blog",link:"/blog",component:Object(g.jsx)(V,{})}],hidden:[]},Me=function(e){Object(b.a)(n,e);var t=Object(m.a)(n);function n(){return Object(p.a)(this,n),t.apply(this,arguments)}return Object(u.a)(n,[{key:"render",value:function(){return Object(g.jsx)("div",{style:{display:"flex",justifyContent:"center",alignItems:"center",height:"80vh",padding:"50px"},children:Object(g.jsx)("h1",{style:{fontSize:"50px",textAlign:"center"},children:"This page does not exist."})})}}]),n}(a.Component);function Pe(){var e=i.a.useRef();function t(t){var n;null===(n=e.current)||void 0===n||n.handlePageChange(t)}return i.a.useEffect((function(){t(window.location.pathname)}),[]),Object(g.jsx)(c.a,{children:Object(g.jsx)(l.b,{render:function(n){var a=n.location;return Object(g.jsxs)("div",{style:{position:"absolute",right:0,left:0,bottom:0,top:0},children:[Object(g.jsx)(v,{}),Object(g.jsx)(R,{ref:e}),Object(g.jsx)(d.a,{component:"div",className:"App",children:Object(g.jsx)(h.a,{timeout:300,classNames:"page",children:Object(g.jsxs)(l.d,{location:a,children:[[].concat(Object(r.a)(Te.main),Object(r.a)(Te.hidden)).map((function(e,n){return Object(g.jsx)(l.b,{path:e.link,exact:!0,render:function(){return t(e.link),Object(g.jsxs)("div",{style:{position:"absolute",right:0,left:0,bottom:0,top:0},children:[Object(g.jsxs)("div",{style:{minHeight:"calc(100vh - 162px)"},children:["/blog"!==e.link?Object(g.jsx)(L,{}):Object(g.jsx)("div",{}),e.component]}),"/blog"!==e.link?Object(g.jsx)(G,{}):Object(g.jsx)("div",{})]})}},e.link)})),H.map((function(e){return void 0!==e.asset&&""!==e.asset&&void 0!==e.webLocation&&""!==e.webLocation?Object(g.jsx)(l.b,{path:"/blog/"+e.webLocation,exact:!0,render:function(){var n;t("/blog");var a=null===(n=e.asset)||void 0===n?void 0:n.includes(".html");return Object(g.jsxs)("div",{style:{position:"absolute",right:0,left:0,bottom:0,top:0},children:[Object(g.jsx)("div",{style:{minHeight:"100vh"},children:Object(g.jsx)(z,{articleData:e.articleData,distill:a,src:"/rvl-lab-utoronto.github.io/"+e.asset})}),a?Object(g.jsx)(g.Fragment,{}):Object(g.jsx)(G,{})]})}},e.title):Object(g.jsx)(l.b,{path:"/404",component:Me},"404")})),oe.map((function(e){return void 0!==e.asset&&""!==e.asset&&void 0!==e.webLocation&&""!==e.webLocation?Object(g.jsx)(l.b,{path:"/research/"+e.webLocation,exact:!0,render:function(){return t("/research"),Object(g.jsxs)("div",{style:{position:"absolute",right:0,left:0,bottom:0,top:0},children:[Object(g.jsx)("div",{style:{minHeight:"100vh"},children:Object(g.jsx)(re,{src:"/rvl-lab-utoronto.github.io/"+e.asset})}),Object(g.jsx)(G,{})]})}},e.title):Object(g.jsx)(l.b,{path:"/404",component:Me},"404")})),Object(g.jsx)(l.b,{path:"/404",component:Me},"404"),Object(g.jsx)(l.a,{from:"*",to:"/404"})]})},a.pathname)})]})}})})}var Le=function(e){e&&e instanceof Function&&n.e(3).then(n.bind(null,407)).then((function(t){var n=t.getCLS,a=t.getFID,i=t.getFCP,o=t.getLCP,s=t.getTTFB;n(e),a(e),i(e),o(e),s(e)}))};s.a.render(Object(g.jsx)(i.a.StrictMode,{children:Object(g.jsx)(Pe,{})}),document.getElementById("root")),Le()},71:function(e,t,n){"use strict";n.r(t),t.default=n.p+"static/media/RVL-icon.0d3d35e6.png"},85:function(e,t,n){"use strict";n.r(t),t.default=n.p+"static/media/globe-solid.cecdc87b.svg"}},[[389,1,2]]]);
//# sourceMappingURL=main.b303368d.chunk.js.map